{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXkR4NjYhezg"
   },
   "source": [
    "# Run Qwen PPO with [verl](https://github.com/volcengine/verl)\n",
    "\n",
    "This tutorial provides a step-by-step guide to using veRL for executing your RLHF pipeline. You can find our [github repo](https://github.com/volcengine/verl/) and [documentation](https://verl.readthedocs.io/en/latest/index.html) for mode details.\n",
    "\n",
    "Please connect to a T4 GPU to run the notebook - It's **free**! However, be aware that the environment is not persisted and may be lost if the session is idle for some time.\n",
    "\n",
    "### You will learn:\n",
    "\n",
    "- How to install veRL from scratch.\n",
    "- How to use existing scripts to run an RLHF pipeline with your own models and data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSDNzNuQkJJh"
   },
   "source": [
    "# Dependency Installation\n",
    "\n",
    "If you are running on paperspace, the driver version may not be the latest. We install torch+cu118 for compatibility reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-10T19:46:07.710480Z",
     "iopub.status.busy": "2025-01-10T19:46:07.710045Z",
     "iopub.status.idle": "2025-01-10T19:47:53.920106Z",
     "shell.execute_reply": "2025-01-10T19:47:53.919641Z",
     "shell.execute_reply.started": "2025-01-10T19:46:07.710459Z"
    },
    "id": "gnfZyMm-3BNC",
    "outputId": "9e8e5116-5344-4c9b-bc34-e9e9be752ff5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.1.1+cu121\n",
      "Uninstalling torch-2.1.1+cu121:\n",
      "  Successfully uninstalled torch-2.1.1+cu121\n",
      "Found existing installation: torchaudio 2.1.1+cu121\n",
      "Uninstalling torchaudio-2.1.1+cu121:\n",
      "  Successfully uninstalled torchaudio-2.1.1+cu121\n",
      "Found existing installation: torchvision 0.16.1+cu121\n",
      "Uninstalling torchvision-0.16.1+cu121:\n",
      "  Successfully uninstalled torchvision-0.16.1+cu121\n",
      "Found existing installation: tensorflow 2.15.0\n",
      "Uninstalling tensorflow-2.15.0:\n",
      "  Successfully uninstalled tensorflow-2.15.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (23.3.2)\n",
      "Collecting pip\n",
      "  Downloading pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (69.0.3)\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-75.8.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (0.35.1)\n",
      "Collecting wheel\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Downloading pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading setuptools-75.8.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m109.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: wheel, setuptools, pip\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.35.1\n",
      "    Uninstalling wheel-0.35.1:\n",
      "      Successfully uninstalled wheel-0.35.1\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 69.0.3\n",
      "    Uninstalling setuptools-69.0.3:\n",
      "      Successfully uninstalled setuptools-69.0.3\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.3.2\n",
      "    Uninstalling pip-23.3.2:\n",
      "      Successfully uninstalled pip-23.3.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gradient-utils 0.5.0 requires wheel<0.36.0,>=0.35.1, but you have wheel 0.45.1 which is incompatible.\n",
      "gradient 2.0.6 requires attrs<=19, but you have attrs 23.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pip-24.3.1 setuptools-75.8.0 wheel-0.45.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Collecting torch==2.4.0\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torch-2.4.0%2Bcu118-cp311-cp311-linux_x86_64.whl (857.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m857.8/857.8 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision==0.19.0\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.19.0%2Bcu118-cp311-cp311-linux_x86_64.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m133.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (2023.6.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m189.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m176.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==9.1.0.70 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m110.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m151.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m169.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m194.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m200.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m211.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu11==2.20.5 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.20.5-py3-none-manylinux2014_x86_64.whl (142.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.9/142.9 MB\u001b[0m \u001b[31m198.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Collecting triton==3.0.0 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m204.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.19.0) (1.26.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.19.0) (9.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.4.0) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.4.0) (1.3.0)\n",
      "Installing collected packages: triton, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch, torchvision\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.1.0\n",
      "    Uninstalling triton-2.1.0:\n",
      "      Successfully uninstalled triton-2.1.0\n",
      "Successfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.20.5 nvidia-nvtx-cu11-11.8.86 torch-2.4.0+cu118 torchvision-0.19.0+cu118 triton-3.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mtorch                             2.4.0+cu118\n",
      "torchvision                       0.19.0+cu118\n",
      "Collecting flash-attn\n",
      "  Downloading flash_attn-2.7.2.post1.tar.gz (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash-attn) (2.4.0+cu118)\n",
      "Collecting einops (from flash-attn)\n",
      "  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.8.86)\n",
      "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flash-attn) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->flash-attn) (1.3.0)\n",
      "Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "Building wheels for collected packages: flash-attn\n",
      "  Building wheel for flash-attn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for flash-attn: filename=flash_attn-2.7.2.post1-cp311-cp311-linux_x86_64.whl size=191966228 sha256=5127904814a2862fb63964b548e9191410f4637f59f3997e4de2000d92a823b4\n",
      "  Stored in directory: /root/.cache/pip/wheels/6a/8b/7d/0ac2b18cb28f4104a1852da090dcf9ea8239ce45fc82bcc4d1\n",
      "Successfully built flash-attn\n",
      "Installing collected packages: einops, flash-attn\n",
      "Successfully installed einops-0.8.0 flash-attn-2.7.2.post1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 uninstall torch torchaudio torchvision tensorflow deepspeed -y\n",
    "!pip3 install --upgrade pip setuptools wheel\n",
    "!pip3 install torch==2.4.0 torchvision==0.19.0 --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip3 list | grep torch\n",
    "!pip3 install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HzV28CwOmruV"
   },
   "source": [
    "## Install and verify verl\n",
    "Now we're ready to install verl!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-10T19:50:55.628112Z",
     "iopub.status.busy": "2025-01-10T19:50:55.627556Z",
     "iopub.status.idle": "2025-01-10T19:51:01.296647Z",
     "shell.execute_reply": "2025-01-10T19:51:01.295796Z",
     "shell.execute_reply.started": "2025-01-10T19:50:55.628089Z"
    },
    "id": "0mtIn1VOk2E7",
    "outputId": "8a83156e-c3aa-4921-97e2-a9472f22ed9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: deepspeed 0.10.3\n",
      "Uninstalling deepspeed-0.10.3:\n",
      "  Successfully uninstalled deepspeed-0.10.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mObtaining file:///notebooks\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from verl==0.1) (0.24.1)\n",
      "Requirement already satisfied: codetiming in /usr/local/lib/python3.11/dist-packages (from verl==0.1) (1.4.0)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from verl==0.1) (2.14.5)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from verl==0.1) (0.3.7)\n",
      "Requirement already satisfied: hydra-core in /usr/local/lib/python3.11/dist-packages (from verl==0.1) (1.3.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from verl==0.1) (1.26.3)\n",
      "Requirement already satisfied: pybind11 in /usr/local/lib/python3.11/dist-packages (from verl==0.1) (2.13.6)\n",
      "Requirement already satisfied: ray in /usr/local/lib/python3.11/dist-packages (from verl==0.1) (2.40.0)\n",
      "Requirement already satisfied: tensordict in /usr/local/lib/python3.11/dist-packages (from verl==0.1) (0.5.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from verl==0.1) (4.48.0)\n",
      "Requirement already satisfied: vllm<=0.6.3 in /usr/local/lib/python3.11/dist-packages (from verl==0.1) (0.6.3)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (5.9.8)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (0.2.0)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (4.66.1)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (9.0.0)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (0.21.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (4.23.4)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (3.9.1)\n",
      "Requirement already satisfied: openai>=1.40.0 in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (1.59.6)\n",
      "Requirement already satisfied: uvicorn[standard] in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (0.34.0)\n",
      "Requirement already satisfied: pydantic>=2.9 in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (2.10.5)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (10.4.0)\n",
      "Requirement already satisfied: prometheus-client>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (0.21.1)\n",
      "Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (7.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (0.7.0)\n",
      "Requirement already satisfied: lm-format-enforcer==0.10.6 in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (0.10.6)\n",
      "Requirement already satisfied: outlines<0.1,>=0.0.43 in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (0.0.46)\n",
      "Requirement already satisfied: typing-extensions>=4.10 in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (4.12.2)\n",
      "Requirement already satisfied: filelock>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (3.13.1)\n",
      "Requirement already satisfied: partial-json-parser in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (0.2.1.1.post5)\n",
      "Requirement already satisfied: pyzmq in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (24.0.1)\n",
      "Requirement already satisfied: msgspec in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (0.19.0)\n",
      "Requirement already satisfied: gguf==0.10.0 in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (0.10.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/lib/python3/dist-packages (from vllm<=0.6.3->verl==0.1) (4.6.4)\n",
      "Requirement already satisfied: mistral-common>=1.4.4 in /usr/local/lib/python3.11/dist-packages (from mistral-common[opencv]>=1.4.4->vllm<=0.6.3->verl==0.1) (1.5.1)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from vllm<=0.6.3->verl==0.1) (5.4.1)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (0.8.0)\n",
      "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (12.560.30)\n",
      "Requirement already satisfied: torch==2.4.0 in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (2.4.0+cu118)\n",
      "Requirement already satisfied: torchvision==0.19 in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (0.19.0+cu118)\n",
      "Requirement already satisfied: xformers==0.0.27.post2 in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (0.0.27.post2)\n",
      "Requirement already satisfied: fastapi!=0.113.*,!=0.114.0,>=0.107.0 in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (0.115.6)\n",
      "Requirement already satisfied: interegular>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from lm-format-enforcer==0.10.6->vllm<=0.6.3->verl==0.1) (0.3.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lm-format-enforcer==0.10.6->vllm<=0.6.3->verl==0.1) (23.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm<=0.6.3->verl==0.1) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm<=0.6.3->verl==0.1) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm<=0.6.3->verl==0.1) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm<=0.6.3->verl==0.1) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm<=0.6.3->verl==0.1) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm<=0.6.3->verl==0.1) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm<=0.6.3->verl==0.1) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm<=0.6.3->verl==0.1) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm<=0.6.3->verl==0.1) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm<=0.6.3->verl==0.1) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm<=0.6.3->verl==0.1) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm<=0.6.3->verl==0.1) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm<=0.6.3->verl==0.1) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm<=0.6.3->verl==0.1) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm<=0.6.3->verl==0.1) (11.8.86)\n",
      "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm<=0.6.3->verl==0.1) (3.0.0)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray->verl==0.1) (8.1.7)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from ray->verl==0.1) (4.21.1)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray->verl==0.1) (1.1.0)\n",
      "Requirement already satisfied: aiosignal in /usr/local/lib/python3.11/dist-packages (from ray->verl==0.1) (1.3.1)\n",
      "Requirement already satisfied: frozenlist in /usr/local/lib/python3.11/dist-packages (from ray->verl==0.1) (1.4.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers->verl==0.1) (0.27.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->verl==0.1) (2023.12.25)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers->verl==0.1) (0.5.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->verl==0.1) (15.0.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->verl==0.1) (2.2.0)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->verl==0.1) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets->verl==0.1) (0.70.15)\n",
      "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.11/dist-packages (from hydra-core->verl==0.1) (2.3.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core->verl==0.1) (4.9.3)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from tensordict->verl==0.1) (2.2.1)\n",
      "Requirement already satisfied: orjson in /usr/local/lib/python3.11/dist-packages (from tensordict->verl==0.1) (3.10.14)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi!=0.113.*,!=0.114.0,>=0.107.0->vllm<=0.6.3->verl==0.1) (0.41.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm<=0.6.3->verl==0.1) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm<=0.6.3->verl==0.1) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm<=0.6.3->verl==0.1) (1.9.4)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray->verl==0.1) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray->verl==0.1) (0.32.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray->verl==0.1) (0.17.1)\n",
      "Requirement already satisfied: opencv-python-headless<5.0.0,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mistral-common[opencv]>=1.4.4->vllm<=0.6.3->verl==0.1) (4.10.0.84)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.40.0->vllm<=0.6.3->verl==0.1) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.40.0->vllm<=0.6.3->verl==0.1) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.40.0->vllm<=0.6.3->verl==0.1) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.40.0->vllm<=0.6.3->verl==0.1) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.40.0->vllm<=0.6.3->verl==0.1) (1.3.0)\n",
      "Requirement already satisfied: lark in /usr/local/lib/python3.11/dist-packages (from outlines<0.1,>=0.0.43->vllm<=0.6.3->verl==0.1) (1.2.2)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from outlines<0.1,>=0.0.43->vllm<=0.6.3->verl==0.1) (1.6.0)\n",
      "Requirement already satisfied: diskcache in /usr/local/lib/python3.11/dist-packages (from outlines<0.1,>=0.0.43->vllm<=0.6.3->verl==0.1) (5.6.3)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from outlines<0.1,>=0.0.43->vllm<=0.6.3->verl==0.1) (0.60.0)\n",
      "Requirement already satisfied: pycountry in /usr/local/lib/python3.11/dist-packages (from outlines<0.1,>=0.0.43->vllm<=0.6.3->verl==0.1) (24.6.1)\n",
      "Requirement already satisfied: pyairports in /usr/local/lib/python3.11/dist-packages (from outlines<0.1,>=0.0.43->vllm<=0.6.3->verl==0.1) (2.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm<=0.6.3->verl==0.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm<=0.6.3->verl==0.1) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm<=0.6.3->verl==0.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.26.0->vllm<=0.6.3->verl==0.1) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm<=0.6.3->verl==0.1) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.26.0->vllm<=0.6.3->verl==0.1) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->verl==0.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->datasets->verl==0.1) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->verl==0.1) (2023.4)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->vllm<=0.6.3->verl==0.1) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->vllm<=0.6.3->verl==0.1) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->vllm<=0.6.3->verl==0.1) (1.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->vllm<=0.6.3->verl==0.1) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->vllm<=0.6.3->verl==0.1) (1.0.4)\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->vllm<=0.6.3->verl==0.1) (14.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.40.0->vllm<=0.6.3->verl==0.1) (1.0.7)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->verl==0.1) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.4.0->vllm<=0.6.3->verl==0.1) (2.1.4)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->outlines<0.1,>=0.0.43->vllm<=0.6.3->verl==0.1) (0.43.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.4.0->vllm<=0.6.3->verl==0.1) (1.3.0)\n",
      "Building wheels for collected packages: verl\n",
      "  Building editable for verl (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for verl: filename=verl-0.1-0.editable-py3-none-any.whl size=12976 sha256=1efcc6a2eb5d71750e6d1739adf382fd740b2220773d5c0fec96f4e1602d63b7\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-6nnxs1iw/wheels/92/b1/e0/ce84c2fbc0ed2bc7398e47cccef44e81a78f9916c16dd6e511\n",
      "Successfully built verl\n",
      "Installing collected packages: verl\n",
      "  Attempting uninstall: verl\n",
      "    Found existing installation: verl 0.1\n",
      "    Uninstalling verl-0.1:\n",
      "      Successfully uninstalled verl-0.1\n",
      "Successfully installed verl-0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# In case you run this notebook and have not cloned verl yet:\n",
    "# !git clone https://github.com/volcengine/verl verl_repo\n",
    "\n",
    "!cd /notebooks && pip3 install -e . -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T20:00:54.885471Z",
     "iopub.status.busy": "2025-01-10T20:00:54.884923Z",
     "iopub.status.idle": "2025-01-10T20:00:54.895316Z",
     "shell.execute_reply": "2025-01-10T20:00:54.894508Z",
     "shell.execute_reply.started": "2025-01-10T20:00:54.885453Z"
    },
    "id": "mOBX8Jqc-ZBe"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "try:\n",
    "  assert torch.cuda.is_available() is True\n",
    "  torch.ones(1, dtype=torch.bfloat16).cuda()\n",
    "except AssertionError:\n",
    "  print(\"Please start the machine with a GPU supporting bfloat16 (RTX 5000, A5000, A100, H100, A10, etc)\")\n",
    "\n",
    "try:\n",
    "  import verl\n",
    "except Exception as e:\n",
    "  print(\"Please install verl via pip and restart the kernel\")\n",
    "  raise e\n",
    "\n",
    "import flash_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9mawNxDfo3Uu"
   },
   "source": [
    "# Load Pretrained Language Model\n",
    "\n",
    "verl supports models available in Huggingface transformers (as well as custom Megatron models).\n",
    "\n",
    "Let's download the model first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404,
     "referenced_widgets": [
      "763679906f9248a7a5f4c8de952d98ae",
      "b319db13c64b43a38250342c81708f70",
      "5110a596739443a8a640cfd50030644b",
      "e93bf508749940909c3233904e898497",
      "b45a42483d64410ba245feda17ae3e16",
      "538e82daa19140098a4053da6e23de45",
      "6b14f827b15f4e34be6590a5d2085b64",
      "07f455e5e6dd45b7ba52f78bfc7ec7d6",
      "fdf06125a50249b8878dbf01993306f4",
      "0ab915aba5e14e5bba7ba1c22a682b89",
      "2749b87567ea4b6cbc4cf825e2282615",
      "645fee7bcccd42a794e4aa889c1fe145",
      "aa19071cede44a089d7f3b19227d51e0",
      "412349b6e00b4994bc3f63f8405b3ec2",
      "a921f9b0d3c74381b75aa60f4d1cac1c",
      "b707bf4c56744f05ac9245b07f6d1788",
      "252e651f687e47f3bd20518f2ac5fb9f",
      "835a6a0a56554d158ee40ccc5ccdffc5",
      "be14bccf9f114d9f839c805afef08f61",
      "52268a2d657b4e19badd66f781f68d93",
      "06873240926949d98e13872546c5231d",
      "936061cb57ad445195efc0aa24dd8d66",
      "144df34a87334a6d8eb13055e7a9b9e4",
      "1e9ee1c383074f638a688b029d72bc79",
      "5cfeadb8ff394f38ac2e23f1a66beeb3",
      "0eeef594fb564491ad8d80f86a8fbfdc",
      "771c5ca9460f4539b30f452dd3f36b12",
      "fab6aab315214fcb884529a4dbf84fe5",
      "06e1b9b5d49d4ee3ab8d1a523659bcbf",
      "e3848f0a11f8472fba3ecb624bc86dd9",
      "c7b67dd574ad4c15b36930047553e9d3",
      "9fbafd9fc26748b7889b5c52600f80a8",
      "889e01d618544f7c9a9d748730255007",
      "69e57962129241a689cfd2933b64127c",
      "4bdbe0a8bb434bfc8e2172ecb5189705",
      "b0bbbf7f9f264dfda2c0d6775567e446",
      "6c9485ecc56f4027ad8f3824554e3968",
      "3447ed64518746cabb0176348fc88d96",
      "35e124a16d2945ddbb3ade95ef2b5519",
      "7de86c10755f4e0da7974bdf1815a85d",
      "4957b3690466495997721afab68ad93a",
      "9e2c1dcd2cd643bbb941d6697fcc75a0",
      "b10402691cc3480693dcf49d19336c72",
      "f0350562775a4c4ca83772a78d05122b",
      "1a382959fdeb4554827397823284d2fa",
      "f52d7af1a82249a3aa7785476e10c2ad",
      "afcc65785fef4b71b03ac83a4b14d97f",
      "c0b19ca098a443598c662921832e8799",
      "ca24445f8af44c8397f12d15d66eebf5",
      "6cd310d2188d424eb20c3bf83ac34f56",
      "ddecda628c6a4a5680b4241633153ebd",
      "e49f1b46d8ae4c3e8f894b1f411922b9",
      "0c9b8ffe4b8c4b5ca72a21cc54a1feb9",
      "c3651669cb084d86b9b8c427c665d185",
      "35bacfb8aa4c4a25bf8ce2d13a00f2b8",
      "c1020ed4d8a44747838ed59287d284ed",
      "a726ef24d10c42bf859e4c76cebde672",
      "40259328dd5e4256939d7b1a3f038d98",
      "ee0b85738cbf4376a6427fadbdecfad7",
      "1491cbb53c6e4bfb9d17cf123dea83dd",
      "5c8c3c4d700540f089f671d4f5d0dd9f",
      "7c45a87d87f44b2384a4fd316ae36663",
      "866c770e39b64dfd9764de755f6a9ec5",
      "2babfcd555104f9d8ecf98e164ec40fc",
      "7920655156a44e629514673dde2b9663",
      "c24df93c305e42cdbaed3d6111d72010",
      "c0e97dba53284330b0fb8cefc852d552",
      "4d1a260957214732940766c874d3a02b",
      "89a180c90767474b8e699e264620666e",
      "7363ebea3a3a4f55b69b2d813c3b2fa5",
      "d49791321218419d8b7af314dd904777",
      "e6b66ca90c9c4b0ead5153e4a07cdc86",
      "3e1dd2fd3bb049ab83aa987d748f5b9e",
      "a1255e85757e495a86ae366857fb64f1",
      "6f3742161c4f4bcc891c82aff7ece69f",
      "e9f9be6fa1744f3380d21c451bc81555",
      "c5024f35870446a0ae8fd747101ab719"
     ]
    },
    "execution": {
     "iopub.execute_input": "2025-01-10T19:53:26.679385Z",
     "iopub.status.busy": "2025-01-10T19:53:26.678619Z",
     "iopub.status.idle": "2025-01-10T19:53:38.942743Z",
     "shell.execute_reply": "2025-01-10T19:53:38.942279Z",
     "shell.execute_reply.started": "2025-01-10T19:53:26.679360Z"
    },
    "id": "k8FsgBYnpR-R",
    "outputId": "57e0e9ae-2c9e-498d-849f-7eafe59c4c03"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef514919a70341bbb71f8948fbb5298e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  58%|#####8    | 577M/988M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d180c42229894ec0bb02f998cfe4a53e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d9183289ef6431b927124b85263266b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d03fb12f6b64104acd66d464383315b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab29223f14f24ab09dc6e3966c1a6c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "635a5549f80b4189a67b9f92792b9483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.text_generation.TextGenerationPipeline at 0x7f0d60fcb010>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.pipeline('text-generation', model='Qwen/Qwen2.5-0.5B-Instruct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zWlDQ6EjnBWz"
   },
   "source": [
    "# Dataset preparation\n",
    "\n",
    "We train with the Grade School Math 8K (GSM8k) task in this demo. The dataset is downloaded from huggingface [gsm8k](https://huggingface.co/datasets/openai/gsm8k) and below are some samples:\n",
    "\n",
    "\n",
    "**Prompt**\n",
    "\n",
    "Katy makes coffee using teaspoons of sugar and cups of water in the ratio of 7:13. If she used a total of 120 teaspoons of sugar and cups of water, calculate the number of teaspoonfuls of sugar she used.\n",
    "\n",
    "**Solution**\n",
    "\n",
    "The total ratio representing the ingredients she used to make the coffee is 7+13 = <<7+13=20>>20 Since the fraction representing the number of teaspoons she used is 7/20, she used 7/20120 = <<7/20120=42>>42 #### 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-10T19:53:54.928717Z",
     "iopub.status.busy": "2025-01-10T19:53:54.928370Z",
     "iopub.status.idle": "2025-01-10T19:54:01.616904Z",
     "shell.execute_reply": "2025-01-10T19:54:01.616364Z",
     "shell.execute_reply.started": "2025-01-10T19:53:54.928657Z"
    },
    "id": "AgRCvb6V6B3A",
    "outputId": "f45c7f69-2f81-4b19-98de-8dc4b869736d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████████████| 7.94k/7.94k [00:00<00:00, 21.6MB/s]\n",
      "Downloading data files:   0%|                             | 0/2 [00:00<?, ?it/s]\n",
      "Downloading data:   0%|                             | 0.00/2.31M [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data: 100%|████████████████████| 2.31M/2.31M [00:00<00:00, 12.8MB/s]\u001b[A\n",
      "Downloading data files:  50%|██████████▌          | 1/2 [00:00<00:00,  5.49it/s]\n",
      "Downloading data: 100%|██████████████████████| 419k/419k [00:00<00:00, 9.82MB/s]\u001b[A\n",
      "Downloading data files: 100%|█████████████████████| 2/2 [00:00<00:00,  8.83it/s]\n",
      "Extracting data files: 100%|████████████████████| 2/2 [00:00<00:00, 2024.77it/s]\n",
      "Generating train split: 100%|████| 7473/7473 [00:00<00:00, 138775.15 examples/s]\n",
      "Generating test split: 100%|█████| 1319/1319 [00:00<00:00, 114970.95 examples/s]\n",
      "Map: 100%|████████████████████████| 7473/7473 [00:00<00:00, 21158.27 examples/s]\n",
      "Map: 100%|████████████████████████| 1319/1319 [00:00<00:00, 22872.60 examples/s]\n",
      "Creating parquet from Arrow format: 100%|████████| 8/8 [00:00<00:00, 243.76ba/s]\n",
      "Creating parquet from Arrow format: 100%|████████| 2/2 [00:00<00:00, 332.12ba/s]\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ~/data/gsm8k\n",
    "!python3 /notebooks/examples/data_preprocess/gsm8k.py --local_dir ~/data/gsm8k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPZZKBxunAoj"
   },
   "source": [
    "# the reward\n",
    "\n",
    "We use a rule-based reward model. We force the model to produce a final answer following 4 `#` as shown in the solution. We extract the final answer from both the solution and model's output using regular expression matching. We compare them and assign a reward of 1 to correct answer, 0.1 to incorrect answer and 0 to no answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-10T19:24:06.737019Z",
     "iopub.status.busy": "2025-01-10T19:24:06.736706Z",
     "iopub.status.idle": "2025-01-10T19:24:06.748488Z",
     "shell.execute_reply": "2025-01-10T19:24:06.747507Z",
     "shell.execute_reply.started": "2025-01-10T19:24:06.736992Z"
    },
    "id": "SjjLVuO60WD1",
    "outputId": "affb562c-7f6c-41f7-ef47-4dfea0020e90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def compute_score(solution_str, ground_truth, method='strict', format_score=0., score=1.):\n",
      "    \"\"\"The scoring function for GSM8k.\n",
      "\n",
      "    Reference: Trung, Luong, et al. \"Reft: Reasoning with reinforced fine-tuning.\" Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2024.\n",
      "\n",
      "    Args:\n",
      "        solution_str: the solution text\n",
      "        ground_truth: the ground truth\n",
      "        method: the method to extract the solution, choices are 'strict' and 'flexible'\n",
      "        format_score: the score for the format\n",
      "        score: the score for the correct answer\n",
      "    \"\"\"\n",
      "    answer = extract_solution(solution_str=solution_str, method=method)\n",
      "    if answer is None:\n",
      "        return 0\n",
      "    else:\n",
      "        if answer == ground_truth:\n",
      "            return score\n",
      "        else:\n",
      "            return format_score\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "from verl.utils.reward_score.gsm8k import compute_score as gsm8k_reward\n",
    "print(inspect.getsource(gsm8k_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPBGPdSD0sCF"
   },
   "source": [
    "# Run the RL Pipeline\n",
    "Let's start with the Proximal Policy Optimization (PPO) algorithm,  one of the most widely used methods for post-training large language models.\n",
    "\n",
    "The main entry point of the PPO algorithm example is: `main_ppo.py`. A detailed guide to understanding the code architecture of `main_ppo.py` is available [here](https://verl.readthedocs.io/en/latest/examples/ppo_code_architecture.html).\n",
    "\n",
    "In this tutorial, we will demonstrate how to run the PPO algorithm with **Qwen 2.5-0.5B** by setting:\n",
    "- `trainer.n_gpus_per_node`: Number of GPUs per node.\n",
    "\n",
    "- `actor_rollout_ref.rollout.tensor_model_parallel_size`: TP size for rollout. Only effective for vllm.\n",
    "\n",
    "- `actor_rollout_ref/critic.model.path`: Huggingface model path. This can be either local path or HDFS path. For HDFS path, we provide utils to download it to DRAM and convert the HDFS path to local path.\n",
    "\n",
    "- `data.train_batch_size`: Batch size sampled for one training iteration of different RL algorithms.\n",
    "\n",
    "- `data.max_prompt_length`: Maximum prompt length. All prompts will be left-padded to this length. An error will be reported if the length is too long.\n",
    "\n",
    "- `data.max_response_length`: Maximum response length. Rollout in RL algorithms (e.g. PPO) generates up to this length.\n",
    "\n",
    "- `actor_rollout_ref.actor.ppo_mini_batch_size`: One sample is split into multiple sub-batches with batch_size=ppo_mini_batch_size for PPO updates.\n",
    "\n",
    "- `actor_rollout_ref/critic.actor.ppo_micro_batch_size`: Similar to gradient accumulation, the micro_batch_size for one forward pass, trading speed for GPU memory.\n",
    "\n",
    "The full configuration explanation is available [here](https://verl.readthedocs.io/en/latest/examples/config.html).\n",
    "\n",
    "The training may take long time to finish. It will output:\n",
    "\n",
    "- generated sentences.\n",
    "\n",
    "- step information with RL metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-10T20:02:17.018958Z",
     "iopub.status.busy": "2025-01-10T20:02:17.018412Z",
     "iopub.status.idle": "2025-01-10T20:04:38.148020Z",
     "shell.execute_reply": "2025-01-10T20:04:38.147116Z",
     "shell.execute_reply.started": "2025-01-10T20:02:17.018933Z"
    },
    "id": "GvyEebBB4eCA",
    "outputId": "a0bb8f75-6f79-456c-c71f-254c84503763"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-10 20:02:21,161\tERROR utils.py:535 -- Unexpected error calculating docker cpuset ids.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/utils.py\", line 532, in _get_docker_cpus\n",
      "    cpu_ids.append(int(num_or_range))\n",
      "                   ^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: '\\n'\n",
      "2025-01-10 20:02:21,230\tINFO worker.py:1821 -- Started a local Ray instance.\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m {'actor_rollout_ref': {'actor': {'clip_ratio': 0.2,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                  'entropy_coeff': 0.001,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                  'fsdp_config': {'grad_offload': False,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                                  'optimizer_offload': False,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                                  'param_offload': False,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                                  'wrap_policy': {'min_num_params': 0}},\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                  'grad_clip': 1.0,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                  'optim': {'lr': 1e-06,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                            'lr_warmup_steps_ratio': 0.0,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                            'min_lr_ratio': None,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                            'total_training_steps': -1,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                            'warmup_style': 'constant'},\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                  'ppo_epochs': 1,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                  'ppo_micro_batch_size': 1,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                  'ppo_mini_batch_size': 64,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                  'shuffle': True,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                  'strategy': 'fsdp'},\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                        'hybrid_engine': True,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                        'model': {'enable_gradient_checkpointing': False,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                  'external_lib': None,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                  'override_config': {},\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                  'path': 'Qwen/Qwen2.5-0.5B-Instruct'},\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                        'ref': {'fsdp_config': {'param_offload': False,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                                'wrap_policy': {'min_num_params': 0}},\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                'log_prob_micro_batch_size': 1},\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                        'rollout': {'do_sample': True,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                    'dtype': 'bfloat16',\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                    'enforce_eager': True,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                    'free_cache_engine': True,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                    'gpu_memory_utilization': 0.4,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                    'ignore_eos': False,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                    'load_format': 'dummy_dtensor',\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                    'log_prob_micro_batch_size': 1,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                    'max_num_batched_tokens': 8192,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                    'max_num_seqs': 1024,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                    'n': 1,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                    'name': 'vllm',\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                    'prompt_length': 512,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                    'response_length': 256,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                    'temperature': 1.0,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                    'tensor_model_parallel_size': 1,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                    'top_k': -1,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                    'top_p': 1}},\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m  'algorithm': {'adv_estimator': 'gae',\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                'gamma': 1.0,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                'kl_ctrl': {'kl_coef': 0.001, 'type': 'fixed'},\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                'kl_penalty': 'kl',\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                'lam': 1.0},\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m  'critic': {'cliprange_value': 0.5,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m             'forward_micro_batch_size': 1,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m             'grad_clip': 1.0,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m             'model': {'enable_gradient_checkpointing': False,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                       'external_lib': None,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                       'fsdp_config': {'grad_offload': False,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                       'optimizer_offload': False,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                       'param_offload': False,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                       'wrap_policy': {'min_num_params': 0}},\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                       'override_config': {},\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                       'path': 'Qwen/Qwen2.5-0.5B-Instruct',\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                       'tokenizer_path': 'Qwen/Qwen2.5-0.5B-Instruct'},\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m             'optim': {'lr': 1e-05,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                       'lr_warmup_steps_ratio': 0.0,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                       'min_lr_ratio': None,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                       'total_training_steps': -1,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                       'warmup_style': 'constant'},\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m             'ppo_epochs': 1,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m             'ppo_micro_batch_size': 1,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m             'ppo_mini_batch_size': 64,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m             'shuffle': True,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m             'strategy': 'fsdp'},\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m  'data': {'max_prompt_length': 512,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m           'max_response_length': 256,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m           'prompt_key': 'prompt',\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m           'return_raw_chat': False,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m           'return_raw_input_ids': False,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m           'tokenizer': None,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m           'train_batch_size': 256,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m           'train_files': '/root/data/gsm8k/train.parquet',\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m           'val_batch_size': 1312,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m           'val_files': '/root/data/gsm8k/test.parquet'},\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m  'reward_model': {'enable': False,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                   'max_length': None,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                   'micro_batch_size': 64,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                   'model': {'external_lib': None,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                             'fsdp_config': {'min_num_params': 0,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                                             'param_offload': False},\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                             'input_tokenizer': 'Qwen/Qwen2.5-0.5B-Instruct',\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1'},\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m                   'strategy': 'fsdp'},\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m  'trainer': {'critic_warmup': 0,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m              'default_hdfs_dir': None,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m              'default_local_dir': 'checkpoints/verl_examples/gsm8k',\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m              'experiment_name': 'gsm8k',\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m              'logger': ['console'],\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m              'n_gpus_per_node': 1,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m              'nnodes': 1,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m              'project_name': 'verl_examples',\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m              'save_freq': 10,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m              'test_freq': 10,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m              'total_epochs': 15,\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m              'val_before_train': False}}\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m original dataset len: 7473\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m filter dataset len: 7473\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m original dataset len: 1319\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m filter dataset len: 1319\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m Size of train dataloader: 29\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m Size of val dataloader: 1\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m Critic overriding config {'bos_token_id': None, 'eos_token_id': 151645, 'pad_token_id': 151643}\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained(\"openai/whisper-tiny\", attn_implementation=\"flash_attention_2\", torch_dtype=torch.float16)`\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m /usr/local/lib/python3.11/dist-packages/torch/distributed/fsdp/_init_utils.py:440: UserWarning: FSDP is switching to use `NO_SHARD` instead of ShardingStrategy.FULL_SHARD since the world size is 1.\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m Qwen2ForCausalLM contains 494.03M parameters\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m Before critic FSDP, memory allocated (GB): 0.0, memory reserved (GB): 0.0\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m NCCL version 2.20.5+cuda11.0\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m After critic FSDP, memory allocated (GB): 1.8410840034484863, memory reserved (GB): 2.95703125\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m Total steps: 435, num_warmup_steps: 0\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m Model config after override: Qwen2Config {\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"_name_or_path\": \"Qwen/Qwen2.5-0.5B-Instruct\",\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"architectures\": [\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m     \"Qwen2ForCausalLM\"\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   ],\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"attention_dropout\": 0.0,\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"eos_token_id\": 151645,\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"hidden_act\": \"silu\",\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"hidden_size\": 896,\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"initializer_range\": 0.02,\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"intermediate_size\": 4864,\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"max_position_embeddings\": 32768,\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"max_window_layers\": 21,\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"model_type\": \"qwen2\",\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"num_attention_heads\": 14,\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"num_hidden_layers\": 24,\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"num_key_value_heads\": 2,\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"pad_token_id\": 151643,\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"rms_norm_eps\": 1e-06,\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"rope_scaling\": null,\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"rope_theta\": 1000000.0,\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"sliding_window\": null,\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"tie_word_embeddings\": true,\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"torch_dtype\": \"bfloat16\",\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"transformers_version\": \"4.48.0\",\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"use_cache\": true,\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"use_sliding_window\": false,\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"vocab_size\": 151936\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m }\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m \n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m /usr/local/lib/python3.11/dist-packages/torch/distributed/fsdp/_init_utils.py:440: UserWarning: FSDP is switching to use `NO_SHARD` instead of ShardingStrategy.FULL_SHARD since the world size is 1.\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m Qwen2ForCausalLM contains 494.03M parameters\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x7fa7c6e3af20>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m Model config after override: Qwen2Config {\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"_name_or_path\": \"Qwen/Qwen2.5-0.5B-Instruct\",\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"architectures\": [\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m     \"Qwen2ForCausalLM\"\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   ],\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"attention_dropout\": 0.0,\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"eos_token_id\": 151645,\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"hidden_act\": \"silu\",\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"hidden_size\": 896,\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"initializer_range\": 0.02,\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"intermediate_size\": 4864,\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"max_position_embeddings\": 32768,\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"max_window_layers\": 21,\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"model_type\": \"qwen2\",\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"num_attention_heads\": 14,\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"num_hidden_layers\": 24,\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"num_key_value_heads\": 2,\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"pad_token_id\": 151643,\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"rms_norm_eps\": 1e-06,\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"rope_scaling\": null,\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"rope_theta\": 1000000.0,\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"sliding_window\": null,\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"tie_word_embeddings\": true,\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"torch_dtype\": \"bfloat16\",\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"transformers_version\": \"4.48.0\",\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"use_cache\": true,\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"use_sliding_window\": false,\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   \"vocab_size\": 151936\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m }\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m \n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m /usr/local/lib/python3.11/dist-packages/torch/distributed/fsdp/_init_utils.py:440: UserWarning: FSDP is switching to use `NO_SHARD` instead of ShardingStrategy.FULL_SHARD since the world size is 1.\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m Qwen2ForCausalLM contains 494.03M parameters\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x7fa7c6e3af20>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m Total steps: 435, num_warmup_steps: 0\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m /usr/local/lib/python3.11/dist-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m No module named 'vllm._version'\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   from vllm.version import __version__ as VLLM_VERSION\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m Before building vllm rollout, memory allocated (GB): 4.602716445922852, memory reserved (GB): 5.78125\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m WARNING 01-10 20:02:46 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m local rank 0\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m no hf weight loader need to be updated\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m before init cache memory allocated: 5.94458624GB, reserved: 6.067060736GB\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m after init cache memory allocated: 8.259842048GB, reserved: 8.382316544GB\n",
      "\u001b[36m(main_task pid=2286)\u001b[0m Using LocalLogger is deprecated. The constructor API will change \n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m /usr/local/lib/python3.11/dist-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 256, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m After building vllm rollout, memory allocated (GB): 6.771177291870117, memory reserved (GB): 7.806640625\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m After building sharding manager, memory allocated (GB): 6.771177291870117, memory reserved (GB): 7.806640625\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m /usr/local/lib/python3.11/dist-packages/torch/distributed/fsdp/_state_dict_utils.py:773: UserWarning: When using ``NO_SHARD`` for ``ShardingStrategy``, full_state_dict willbe returned.\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m /usr/local/lib/python3.11/dist-packages/torch/distributed/fsdp/_state_dict_utils.py:716: UserWarning: When using ``NO_SHARD`` for ``ShardingStrategy``, full_state_dict willbe returned.\n",
      "\u001b[36m(WorkerDict pid=2396)\u001b[0m   warnings.warn(\n",
      "Error executing job with overrides: ['data.train_files=/root/data/gsm8k/train.parquet', 'data.val_files=/root/data/gsm8k/test.parquet', 'data.train_batch_size=256', 'data.val_batch_size=1312', 'data.max_prompt_length=512', 'data.max_response_length=256', 'actor_rollout_ref.model.path=Qwen/Qwen2.5-0.5B-Instruct', 'actor_rollout_ref.actor.optim.lr=1e-6', 'actor_rollout_ref.actor.ppo_mini_batch_size=64', 'actor_rollout_ref.actor.ppo_micro_batch_size=1', 'actor_rollout_ref.rollout.log_prob_micro_batch_size=1', 'actor_rollout_ref.rollout.tensor_model_parallel_size=1', 'actor_rollout_ref.rollout.gpu_memory_utilization=0.4', 'actor_rollout_ref.ref.log_prob_micro_batch_size=1', 'critic.optim.lr=1e-5', 'critic.model.path=Qwen/Qwen2.5-0.5B-Instruct', 'critic.ppo_micro_batch_size=1', 'algorithm.kl_ctrl.kl_coef=0.001', 'trainer.logger=[console]', '+trainer.val_before_train=False', 'trainer.default_hdfs_dir=null', 'trainer.n_gpus_per_node=1', 'trainer.nnodes=1', 'trainer.save_freq=10', 'trainer.test_freq=10', 'trainer.total_epochs=15', 'actor_rollout_ref.actor.ppo_micro_batch_size=1', 'critic.ppo_micro_batch_size=1', 'actor_rollout_ref.actor.fsdp_config.param_offload=False', 'critic.model.fsdp_config.param_offload=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/notebooks/verl/trainer/main_ppo.py\", line 99, in main\n",
      "    ray.get(main_task.remote(config))\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 2755, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 906, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(OutOfMemoryError): \u001b[36mray::main_task()\u001b[39m (pid=2286, ip=10.38.247.239)\n",
      "  File \"/notebooks/verl/trainer/main_ppo.py\", line 185, in main_task\n",
      "    trainer.fit()\n",
      "  File \"/notebooks/verl/trainer/ppo/ray_trainer.py\", line 545, in fit\n",
      "    actor_output = self.actor_rollout_wg.update_actor(batch)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/notebooks/verl/single_controller/ray/base.py\", line 42, in func\n",
      "    output = ray.get(output)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ray.exceptions.RayTaskError(OutOfMemoryError): \u001b[36mray::WorkerDict.actor_rollout_update_actor()\u001b[39m (pid=2396, ip=10.38.247.239, actor_id=e1e7e95586232510ed8b69f901000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7fa7c1bf06d0>)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/notebooks/verl/single_controller/ray/base.py\", line 399, in func\n",
      "    return getattr(self.worker_dict[key], name)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/notebooks/verl/single_controller/base/decorator.py\", line 404, in inner\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/notebooks/verl/workers/fsdp_workers.py\", line 324, in update_actor\n",
      "    metrics = self.actor.update_policy(data=data)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/notebooks/verl/workers/actor/dp_actor.py\", line 163, in update_policy\n",
      "    grad_norm = self._optimizer_step()\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/notebooks/verl/workers/actor/dp_actor.py\", line 74, in _optimizer_step\n",
      "    self.actor_optimizer.step()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\", line 89, in _use_grad\n",
      "    ret = func(self, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py\", line 216, in step\n",
      "    has_complex = self._init_group(\n",
      "                  ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py\", line 159, in _init_group\n",
      "    state[\"exp_avg_sq\"] = torch.zeros_like(\n",
      "                          ^^^^^^^^^^^^^^^^^\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 58.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 43.12 MiB is free. Process 2689301 has 2.92 GiB memory in use. Process 2708525 has 12.75 GiB memory in use. Of the allocated memory 12.11 GiB is allocated by PyTorch, and 257.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python3 -m verl.trainer.main_ppo \\\n",
    " data.train_files=$HOME/data/gsm8k/train.parquet \\\n",
    " data.val_files=$HOME/data/gsm8k/test.parquet \\\n",
    " data.train_batch_size=256 \\\n",
    " data.val_batch_size=1312 \\\n",
    " data.max_prompt_length=512 \\\n",
    " data.max_response_length=256 \\\n",
    " actor_rollout_ref.model.path=Qwen/Qwen2.5-0.5B-Instruct \\\n",
    " actor_rollout_ref.actor.optim.lr=1e-6 \\\n",
    " actor_rollout_ref.actor.ppo_mini_batch_size=64 \\\n",
    " actor_rollout_ref.actor.ppo_micro_batch_size=1 \\\n",
    " actor_rollout_ref.rollout.log_prob_micro_batch_size=1 \\\n",
    " actor_rollout_ref.rollout.tensor_model_parallel_size=1 \\\n",
    " actor_rollout_ref.rollout.gpu_memory_utilization=0.4 \\\n",
    " actor_rollout_ref.ref.log_prob_micro_batch_size=1 \\\n",
    " critic.optim.lr=1e-5 \\\n",
    " critic.model.path=Qwen/Qwen2.5-0.5B-Instruct \\\n",
    " critic.ppo_micro_batch_size=1 \\\n",
    " algorithm.kl_ctrl.kl_coef=0.001 \\\n",
    " trainer.logger=['console'] \\\n",
    " +trainer.val_before_train=False \\\n",
    " trainer.default_hdfs_dir=null \\\n",
    " trainer.n_gpus_per_node=1 \\\n",
    " trainer.nnodes=1 \\\n",
    " trainer.save_freq=10 \\\n",
    " trainer.test_freq=10 \\\n",
    " trainer.total_epochs=15 \\\n",
    " actor_rollout_ref.actor.ppo_micro_batch_size=1 \\\n",
    " critic.ppo_micro_batch_size=1 \\\n",
    " actor_rollout_ref.actor.fsdp_config.param_offload=False \\\n",
    " critic.model.fsdp_config.param_offload=False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zSn7lNlZ2vfL"
   },
   "source": [
    "# Stop and clean up resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-10T20:02:04.704962Z",
     "iopub.status.busy": "2025-01-10T20:02:04.704352Z",
     "iopub.status.idle": "2025-01-10T20:02:06.910321Z",
     "shell.execute_reply": "2025-01-10T20:02:06.909533Z",
     "shell.execute_reply.started": "2025-01-10T20:02:04.704933Z"
    },
    "id": "QuJ-LgdTAPkb",
    "outputId": "64f2ef75-4a6d-4a62-922e-3d09b33a8a44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not find any active Ray processes.\n",
      "\u001b[0mFri Jan 10 20:02:06 2025       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A4000    Off  | 00000000:00:05.0 Off |                  Off |\n",
      "| 41%   36C    P8    15W / 140W |   2995MiB / 16376MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!ray stop\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06873240926949d98e13872546c5231d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06e1b9b5d49d4ee3ab8d1a523659bcbf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "07f455e5e6dd45b7ba52f78bfc7ec7d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ab915aba5e14e5bba7ba1c22a682b89": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c9b8ffe4b8c4b5ca72a21cc54a1feb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0eeef594fb564491ad8d80f86a8fbfdc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9fbafd9fc26748b7889b5c52600f80a8",
      "placeholder": "​",
      "style": "IPY_MODEL_889e01d618544f7c9a9d748730255007",
      "value": " 242/242 [00:00&lt;00:00, 15.3kB/s]"
     }
    },
    "144df34a87334a6d8eb13055e7a9b9e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1e9ee1c383074f638a688b029d72bc79",
       "IPY_MODEL_5cfeadb8ff394f38ac2e23f1a66beeb3",
       "IPY_MODEL_0eeef594fb564491ad8d80f86a8fbfdc"
      ],
      "layout": "IPY_MODEL_771c5ca9460f4539b30f452dd3f36b12"
     }
    },
    "1491cbb53c6e4bfb9d17cf123dea83dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a382959fdeb4554827397823284d2fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f52d7af1a82249a3aa7785476e10c2ad",
       "IPY_MODEL_afcc65785fef4b71b03ac83a4b14d97f",
       "IPY_MODEL_c0b19ca098a443598c662921832e8799"
      ],
      "layout": "IPY_MODEL_ca24445f8af44c8397f12d15d66eebf5"
     }
    },
    "1e9ee1c383074f638a688b029d72bc79": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fab6aab315214fcb884529a4dbf84fe5",
      "placeholder": "​",
      "style": "IPY_MODEL_06e1b9b5d49d4ee3ab8d1a523659bcbf",
      "value": "generation_config.json: 100%"
     }
    },
    "252e651f687e47f3bd20518f2ac5fb9f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2749b87567ea4b6cbc4cf825e2282615": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2babfcd555104f9d8ecf98e164ec40fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3447ed64518746cabb0176348fc88d96": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35bacfb8aa4c4a25bf8ce2d13a00f2b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "35e124a16d2945ddbb3ade95ef2b5519": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e1dd2fd3bb049ab83aa987d748f5b9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "40259328dd5e4256939d7b1a3f038d98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_866c770e39b64dfd9764de755f6a9ec5",
      "max": 1671839,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2babfcd555104f9d8ecf98e164ec40fc",
      "value": 1671839
     }
    },
    "412349b6e00b4994bc3f63f8405b3ec2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be14bccf9f114d9f839c805afef08f61",
      "max": 988097824,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_52268a2d657b4e19badd66f781f68d93",
      "value": 988097824
     }
    },
    "4957b3690466495997721afab68ad93a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4bdbe0a8bb434bfc8e2172ecb5189705": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_35e124a16d2945ddbb3ade95ef2b5519",
      "placeholder": "​",
      "style": "IPY_MODEL_7de86c10755f4e0da7974bdf1815a85d",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "4d1a260957214732940766c874d3a02b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e6b66ca90c9c4b0ead5153e4a07cdc86",
      "placeholder": "​",
      "style": "IPY_MODEL_3e1dd2fd3bb049ab83aa987d748f5b9e",
      "value": "tokenizer.json: 100%"
     }
    },
    "5110a596739443a8a640cfd50030644b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_07f455e5e6dd45b7ba52f78bfc7ec7d6",
      "max": 659,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fdf06125a50249b8878dbf01993306f4",
      "value": 659
     }
    },
    "52268a2d657b4e19badd66f781f68d93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "538e82daa19140098a4053da6e23de45": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c8c3c4d700540f089f671d4f5d0dd9f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5cfeadb8ff394f38ac2e23f1a66beeb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e3848f0a11f8472fba3ecb624bc86dd9",
      "max": 242,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c7b67dd574ad4c15b36930047553e9d3",
      "value": 242
     }
    },
    "645fee7bcccd42a794e4aa889c1fe145": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_aa19071cede44a089d7f3b19227d51e0",
       "IPY_MODEL_412349b6e00b4994bc3f63f8405b3ec2",
       "IPY_MODEL_a921f9b0d3c74381b75aa60f4d1cac1c"
      ],
      "layout": "IPY_MODEL_b707bf4c56744f05ac9245b07f6d1788"
     }
    },
    "69e57962129241a689cfd2933b64127c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4bdbe0a8bb434bfc8e2172ecb5189705",
       "IPY_MODEL_b0bbbf7f9f264dfda2c0d6775567e446",
       "IPY_MODEL_6c9485ecc56f4027ad8f3824554e3968"
      ],
      "layout": "IPY_MODEL_3447ed64518746cabb0176348fc88d96"
     }
    },
    "6b14f827b15f4e34be6590a5d2085b64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6c9485ecc56f4027ad8f3824554e3968": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b10402691cc3480693dcf49d19336c72",
      "placeholder": "​",
      "style": "IPY_MODEL_f0350562775a4c4ca83772a78d05122b",
      "value": " 7.30k/7.30k [00:00&lt;00:00, 497kB/s]"
     }
    },
    "6cd310d2188d424eb20c3bf83ac34f56": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f3742161c4f4bcc891c82aff7ece69f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7363ebea3a3a4f55b69b2d813c3b2fa5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e9f9be6fa1744f3380d21c451bc81555",
      "placeholder": "​",
      "style": "IPY_MODEL_c5024f35870446a0ae8fd747101ab719",
      "value": " 7.03M/7.03M [00:01&lt;00:00, 6.03MB/s]"
     }
    },
    "763679906f9248a7a5f4c8de952d98ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b319db13c64b43a38250342c81708f70",
       "IPY_MODEL_5110a596739443a8a640cfd50030644b",
       "IPY_MODEL_e93bf508749940909c3233904e898497"
      ],
      "layout": "IPY_MODEL_b45a42483d64410ba245feda17ae3e16"
     }
    },
    "771c5ca9460f4539b30f452dd3f36b12": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7920655156a44e629514673dde2b9663": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c45a87d87f44b2384a4fd316ae36663": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7de86c10755f4e0da7974bdf1815a85d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "835a6a0a56554d158ee40ccc5ccdffc5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "866c770e39b64dfd9764de755f6a9ec5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "889e01d618544f7c9a9d748730255007": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "89a180c90767474b8e699e264620666e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a1255e85757e495a86ae366857fb64f1",
      "max": 7031645,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6f3742161c4f4bcc891c82aff7ece69f",
      "value": 7031645
     }
    },
    "936061cb57ad445195efc0aa24dd8d66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9e2c1dcd2cd643bbb941d6697fcc75a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9fbafd9fc26748b7889b5c52600f80a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1255e85757e495a86ae366857fb64f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a726ef24d10c42bf859e4c76cebde672": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c8c3c4d700540f089f671d4f5d0dd9f",
      "placeholder": "​",
      "style": "IPY_MODEL_7c45a87d87f44b2384a4fd316ae36663",
      "value": "merges.txt: 100%"
     }
    },
    "a921f9b0d3c74381b75aa60f4d1cac1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06873240926949d98e13872546c5231d",
      "placeholder": "​",
      "style": "IPY_MODEL_936061cb57ad445195efc0aa24dd8d66",
      "value": " 988M/988M [00:24&lt;00:00, 40.9MB/s]"
     }
    },
    "aa19071cede44a089d7f3b19227d51e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_252e651f687e47f3bd20518f2ac5fb9f",
      "placeholder": "​",
      "style": "IPY_MODEL_835a6a0a56554d158ee40ccc5ccdffc5",
      "value": "model.safetensors: 100%"
     }
    },
    "afcc65785fef4b71b03ac83a4b14d97f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e49f1b46d8ae4c3e8f894b1f411922b9",
      "max": 2776833,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0c9b8ffe4b8c4b5ca72a21cc54a1feb9",
      "value": 2776833
     }
    },
    "b0bbbf7f9f264dfda2c0d6775567e446": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4957b3690466495997721afab68ad93a",
      "max": 7305,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9e2c1dcd2cd643bbb941d6697fcc75a0",
      "value": 7305
     }
    },
    "b10402691cc3480693dcf49d19336c72": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b319db13c64b43a38250342c81708f70": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_538e82daa19140098a4053da6e23de45",
      "placeholder": "​",
      "style": "IPY_MODEL_6b14f827b15f4e34be6590a5d2085b64",
      "value": "config.json: 100%"
     }
    },
    "b45a42483d64410ba245feda17ae3e16": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b707bf4c56744f05ac9245b07f6d1788": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be14bccf9f114d9f839c805afef08f61": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c0b19ca098a443598c662921832e8799": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c3651669cb084d86b9b8c427c665d185",
      "placeholder": "​",
      "style": "IPY_MODEL_35bacfb8aa4c4a25bf8ce2d13a00f2b8",
      "value": " 2.78M/2.78M [00:01&lt;00:00, 2.42MB/s]"
     }
    },
    "c0e97dba53284330b0fb8cefc852d552": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4d1a260957214732940766c874d3a02b",
       "IPY_MODEL_89a180c90767474b8e699e264620666e",
       "IPY_MODEL_7363ebea3a3a4f55b69b2d813c3b2fa5"
      ],
      "layout": "IPY_MODEL_d49791321218419d8b7af314dd904777"
     }
    },
    "c1020ed4d8a44747838ed59287d284ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a726ef24d10c42bf859e4c76cebde672",
       "IPY_MODEL_40259328dd5e4256939d7b1a3f038d98",
       "IPY_MODEL_ee0b85738cbf4376a6427fadbdecfad7"
      ],
      "layout": "IPY_MODEL_1491cbb53c6e4bfb9d17cf123dea83dd"
     }
    },
    "c24df93c305e42cdbaed3d6111d72010": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c3651669cb084d86b9b8c427c665d185": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5024f35870446a0ae8fd747101ab719": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c7b67dd574ad4c15b36930047553e9d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ca24445f8af44c8397f12d15d66eebf5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d49791321218419d8b7af314dd904777": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ddecda628c6a4a5680b4241633153ebd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e3848f0a11f8472fba3ecb624bc86dd9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e49f1b46d8ae4c3e8f894b1f411922b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6b66ca90c9c4b0ead5153e4a07cdc86": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e93bf508749940909c3233904e898497": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ab915aba5e14e5bba7ba1c22a682b89",
      "placeholder": "​",
      "style": "IPY_MODEL_2749b87567ea4b6cbc4cf825e2282615",
      "value": " 659/659 [00:00&lt;00:00, 27.5kB/s]"
     }
    },
    "e9f9be6fa1744f3380d21c451bc81555": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee0b85738cbf4376a6427fadbdecfad7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7920655156a44e629514673dde2b9663",
      "placeholder": "​",
      "style": "IPY_MODEL_c24df93c305e42cdbaed3d6111d72010",
      "value": " 1.67M/1.67M [00:00&lt;00:00, 1.93MB/s]"
     }
    },
    "f0350562775a4c4ca83772a78d05122b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f52d7af1a82249a3aa7785476e10c2ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6cd310d2188d424eb20c3bf83ac34f56",
      "placeholder": "​",
      "style": "IPY_MODEL_ddecda628c6a4a5680b4241633153ebd",
      "value": "vocab.json: 100%"
     }
    },
    "fab6aab315214fcb884529a4dbf84fe5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fdf06125a50249b8878dbf01993306f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
