{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXkR4NjYhezg"
   },
   "source": [
    "# Run Qwen PPO with [verl](https://github.com/volcengine/verl)\n",
    "\n",
    "This tutorial provides a step-by-step guide to using veRL for executing your RLHF pipeline. You can find our [github repo](https://github.com/volcengine/verl/) and [documentation](https://verl.readthedocs.io/en/latest/index.html) for mode details.\n",
    "\n",
    "Please connect to a T4 GPU to run the notebook - It's **free**! However, be aware that the environment is not persisted and may be lost if the session is idle for some time.\n",
    "\n",
    "### You will learn:\n",
    "\n",
    "- How to install veRL from scratch.\n",
    "- How to use existing scripts to run an RLHF pipeline with your own models and data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSDNzNuQkJJh"
   },
   "source": [
    "# Dependency Installation\n",
    "\n",
    "If you are running on paperspace, the driver version may not be the latest. We install torch+cu118 for compatibility reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-10T19:33:30.533377Z",
     "iopub.status.busy": "2025-01-10T19:33:30.532964Z",
     "iopub.status.idle": "2025-01-10T19:34:11.053171Z",
     "shell.execute_reply": "2025-01-10T19:34:11.050841Z",
     "shell.execute_reply.started": "2025-01-10T19:33:30.533363Z"
    },
    "id": "gnfZyMm-3BNC",
    "outputId": "9e8e5116-5344-4c9b-bc34-e9e9be752ff5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.4.0+cu118\n",
      "Uninstalling torch-2.4.0+cu118:\n",
      "  Successfully uninstalled torch-2.4.0+cu118\n",
      "\u001b[33mWARNING: Skipping torchaudio as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: torchvision 0.19.0+cu118\n",
      "Uninstalling torchvision-0.19.0+cu118:\n",
      "  Successfully uninstalled torchvision-0.19.0+cu118\n",
      "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Collecting torch==2.4.0\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torch-2.4.0%2Bcu118-cp311-cp311-linux_x86_64.whl (857.8 MB)\n",
      "Collecting torchvision==0.19.0\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torchvision-0.19.0%2Bcu118-cp311-cp311-linux_x86_64.whl (6.3 MB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (11.8.86)\n",
      "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.0.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.19.0) (1.26.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.19.0) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.4.0) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.4.0) (1.3.0)\n",
      "Installing collected packages: torch, torchvision\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "deepspeed 0.10.3 requires pydantic<2.0.0, but you have pydantic 2.10.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-2.4.0+cu118 torchvision-0.19.0+cu118\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mtorch                             2.4.0+cu118\n",
      "torchvision                       0.19.0+cu118\n",
      "Collecting flash-attn\n",
      "  Using cached flash_attn-2.7.2.post1.tar.gz (3.1 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash-attn) (2.4.0+cu118)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash-attn) (0.8.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.8.86)\n",
      "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flash-attn) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->flash-attn) (1.3.0)\n",
      "Building wheels for collected packages: flash-attn\n",
      "  Building wheel for flash-attn (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[44 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m fatal: not a git repository (or any of the parent directories): .git\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m torch.__version__  = 2.4.0+cu118\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m /usr/local/lib/python3.11/dist-packages/setuptools/__init__.py:80: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Requirements should be satisfied by a PEP 517 installer.\n",
      "  \u001b[31m   \u001b[0m         If you are using pip, you can try `pip install --use-pep517`.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   dist.fetch_build_eggs(dist.setup_requires)\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m Guessing wheel URL:  https://github.com/Dao-AILab/flash-attention/releases/download/v2.7.2.post1/flash_attn-2.7.2.post1+cu11torch2.4cxx11abiFALSE-cp311-cp311-linux_x86_64.whl\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-hw9j8won/flash-attn_be87de26a81b4cedb005bb6f934a2a44/setup.py\", line 505, in <module>\n",
      "  \u001b[31m   \u001b[0m     setup(\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/setuptools/__init__.py\", line 103, in setup\n",
      "  \u001b[31m   \u001b[0m     return distutils.core.setup(**attrs)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/core.py\", line 185, in setup\n",
      "  \u001b[31m   \u001b[0m     return run_commands(dist)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/core.py\", line 201, in run_commands\n",
      "  \u001b[31m   \u001b[0m     dist.run_commands()\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/dist.py\", line 969, in run_commands\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd)\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/setuptools/dist.py\", line 963, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-hw9j8won/flash-attn_be87de26a81b4cedb005bb6f934a2a44/setup.py\", line 473, in run\n",
      "  \u001b[31m   \u001b[0m     impl_tag, abi_tag, plat_tag = self.get_tag()\n",
      "  \u001b[31m   \u001b[0m                                   ^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wheel/bdist_wheel.py\", line 278, in get_tag\n",
      "  \u001b[31m   \u001b[0m     assert tag in supported_tags, \"would build wheel with unsupported tag {}\".format(tag)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m AssertionError: would build wheel with unsupported tag ('cp311', 'cp311', 'linux_x86_64')\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for flash-attn\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for flash-attn\n",
      "Failed to build flash-attn\n",
      "\u001b[31mERROR: Could not build wheels for flash-attn, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 uninstall torch torchaudio torchvision tensorflow -y\n",
    "!pip3 install --upgrade pip setuptools wheel\n",
    "!pip3 install torch==2.4.0 torchvision==0.19.0 --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip3 list | grep torch\n",
    "!pip3 install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HzV28CwOmruV"
   },
   "source": [
    "## Install and verify verl\n",
    "Now we're ready to install verl!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-10T19:19:19.238198Z",
     "iopub.status.busy": "2025-01-10T19:19:19.237876Z",
     "iopub.status.idle": "2025-01-10T19:19:30.059107Z",
     "shell.execute_reply": "2025-01-10T19:19:30.058108Z",
     "shell.execute_reply.started": "2025-01-10T19:19:19.238168Z"
    },
    "id": "0mtIn1VOk2E7",
    "outputId": "8a83156e-c3aa-4921-97e2-a9472f22ed9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///notebooks\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from verl==0.1) (0.24.1)\n",
      "Requirement already satisfied: codetiming in /usr/local/lib/python3.11/dist-packages (from verl==0.1) (1.4.0)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from verl==0.1) (2.14.5)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from verl==0.1) (0.3.7)\n",
      "Requirement already satisfied: hydra-core in /usr/local/lib/python3.11/dist-packages (from verl==0.1) (1.3.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from verl==0.1) (1.26.3)\n",
      "Requirement already satisfied: pybind11 in /usr/local/lib/python3.11/dist-packages (from verl==0.1) (2.13.6)\n",
      "Requirement already satisfied: ray in /usr/local/lib/python3.11/dist-packages (from verl==0.1) (2.40.0)\n",
      "Requirement already satisfied: tensordict in /usr/local/lib/python3.11/dist-packages (from verl==0.1) (0.5.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from verl==0.1) (4.48.0)\n",
      "Requirement already satisfied: vllm<=0.6.3 in /usr/local/lib/python3.11/dist-packages (from verl==0.1) (0.6.3)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (5.9.8)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (0.2.0)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (4.66.1)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (9.0.0)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (0.21.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (4.23.4)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (3.9.1)\n",
      "Requirement already satisfied: openai>=1.40.0 in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (1.59.6)\n",
      "Requirement already satisfied: uvicorn[standard] in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (0.34.0)\n",
      "Requirement already satisfied: pydantic>=2.9 in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (2.10.5)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (10.4.0)\n",
      "Requirement already satisfied: prometheus-client>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (0.21.1)\n",
      "Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (7.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (0.7.0)\n",
      "Requirement already satisfied: lm-format-enforcer==0.10.6 in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (0.10.6)\n",
      "Requirement already satisfied: outlines<0.1,>=0.0.43 in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (0.0.46)\n",
      "Requirement already satisfied: typing-extensions>=4.10 in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (4.12.2)\n",
      "Requirement already satisfied: filelock>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (3.13.1)\n",
      "Requirement already satisfied: partial-json-parser in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (0.2.1.1.post5)\n",
      "Requirement already satisfied: pyzmq in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (24.0.1)\n",
      "Requirement already satisfied: msgspec in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (0.19.0)\n",
      "Requirement already satisfied: gguf==0.10.0 in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (0.10.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/lib/python3/dist-packages (from vllm<=0.6.3->verl==0.1) (4.6.4)\n",
      "Requirement already satisfied: mistral-common>=1.4.4 in /usr/local/lib/python3.11/dist-packages (from mistral-common[opencv]>=1.4.4->vllm<=0.6.3->verl==0.1) (1.5.1)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from vllm<=0.6.3->verl==0.1) (5.4.1)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (0.8.0)\n",
      "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (12.560.30)\n",
      "Requirement already satisfied: torch==2.4.0 in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (2.4.0+cu118)\n",
      "Requirement already satisfied: torchvision==0.19 in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (0.19.0+cu118)\n",
      "Requirement already satisfied: xformers==0.0.27.post2 in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (0.0.27.post2)\n",
      "Requirement already satisfied: fastapi!=0.113.*,!=0.114.0,>=0.107.0 in /usr/local/lib/python3.11/dist-packages (from vllm<=0.6.3->verl==0.1) (0.115.6)\n",
      "Requirement already satisfied: interegular>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from lm-format-enforcer==0.10.6->vllm<=0.6.3->verl==0.1) (0.3.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lm-format-enforcer==0.10.6->vllm<=0.6.3->verl==0.1) (23.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm<=0.6.3->verl==0.1) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm<=0.6.3->verl==0.1) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm<=0.6.3->verl==0.1) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm<=0.6.3->verl==0.1) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm<=0.6.3->verl==0.1) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm<=0.6.3->verl==0.1) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm<=0.6.3->verl==0.1) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm<=0.6.3->verl==0.1) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm<=0.6.3->verl==0.1) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm<=0.6.3->verl==0.1) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm<=0.6.3->verl==0.1) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm<=0.6.3->verl==0.1) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm<=0.6.3->verl==0.1) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm<=0.6.3->verl==0.1) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm<=0.6.3->verl==0.1) (11.8.86)\n",
      "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm<=0.6.3->verl==0.1) (3.0.0)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray->verl==0.1) (8.1.7)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from ray->verl==0.1) (4.21.1)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray->verl==0.1) (1.1.0)\n",
      "Requirement already satisfied: aiosignal in /usr/local/lib/python3.11/dist-packages (from ray->verl==0.1) (1.3.1)\n",
      "Requirement already satisfied: frozenlist in /usr/local/lib/python3.11/dist-packages (from ray->verl==0.1) (1.4.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers->verl==0.1) (0.27.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->verl==0.1) (2023.12.25)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers->verl==0.1) (0.5.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->verl==0.1) (15.0.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->verl==0.1) (2.2.0)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->verl==0.1) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets->verl==0.1) (0.70.15)\n",
      "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.11/dist-packages (from hydra-core->verl==0.1) (2.3.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core->verl==0.1) (4.9.3)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from tensordict->verl==0.1) (2.2.1)\n",
      "Requirement already satisfied: orjson in /usr/local/lib/python3.11/dist-packages (from tensordict->verl==0.1) (3.10.14)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi!=0.113.*,!=0.114.0,>=0.107.0->vllm<=0.6.3->verl==0.1) (0.41.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm<=0.6.3->verl==0.1) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm<=0.6.3->verl==0.1) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm<=0.6.3->verl==0.1) (1.9.4)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray->verl==0.1) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray->verl==0.1) (0.32.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray->verl==0.1) (0.17.1)\n",
      "Requirement already satisfied: opencv-python-headless<5.0.0,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mistral-common[opencv]>=1.4.4->vllm<=0.6.3->verl==0.1) (4.10.0.84)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.40.0->vllm<=0.6.3->verl==0.1) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.40.0->vllm<=0.6.3->verl==0.1) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.40.0->vllm<=0.6.3->verl==0.1) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.40.0->vllm<=0.6.3->verl==0.1) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.40.0->vllm<=0.6.3->verl==0.1) (1.3.0)\n",
      "Requirement already satisfied: lark in /usr/local/lib/python3.11/dist-packages (from outlines<0.1,>=0.0.43->vllm<=0.6.3->verl==0.1) (1.2.2)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from outlines<0.1,>=0.0.43->vllm<=0.6.3->verl==0.1) (1.6.0)\n",
      "Requirement already satisfied: diskcache in /usr/local/lib/python3.11/dist-packages (from outlines<0.1,>=0.0.43->vllm<=0.6.3->verl==0.1) (5.6.3)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from outlines<0.1,>=0.0.43->vllm<=0.6.3->verl==0.1) (0.60.0)\n",
      "Requirement already satisfied: pycountry in /usr/local/lib/python3.11/dist-packages (from outlines<0.1,>=0.0.43->vllm<=0.6.3->verl==0.1) (24.6.1)\n",
      "Requirement already satisfied: pyairports in /usr/local/lib/python3.11/dist-packages (from outlines<0.1,>=0.0.43->vllm<=0.6.3->verl==0.1) (2.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm<=0.6.3->verl==0.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm<=0.6.3->verl==0.1) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm<=0.6.3->verl==0.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.26.0->vllm<=0.6.3->verl==0.1) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm<=0.6.3->verl==0.1) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.26.0->vllm<=0.6.3->verl==0.1) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->verl==0.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->datasets->verl==0.1) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->verl==0.1) (2023.4)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->vllm<=0.6.3->verl==0.1) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->vllm<=0.6.3->verl==0.1) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->vllm<=0.6.3->verl==0.1) (1.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->vllm<=0.6.3->verl==0.1) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->vllm<=0.6.3->verl==0.1) (1.0.4)\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->vllm<=0.6.3->verl==0.1) (14.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.40.0->vllm<=0.6.3->verl==0.1) (1.0.7)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->verl==0.1) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.4.0->vllm<=0.6.3->verl==0.1) (2.1.4)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->outlines<0.1,>=0.0.43->vllm<=0.6.3->verl==0.1) (0.43.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.4.0->vllm<=0.6.3->verl==0.1) (1.3.0)\n",
      "Building wheels for collected packages: verl\n",
      "  Building editable for verl (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for verl: filename=verl-0.1-0.editable-py3-none-any.whl size=12976 sha256=4a371ed24b241d4c48645e2e565c4f7f0d22d8383614715feaf7bea759f981a9\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-9kmk1skq/wheels/92/b1/e0/ce84c2fbc0ed2bc7398e47cccef44e81a78f9916c16dd6e511\n",
      "Successfully built verl\n",
      "Installing collected packages: verl\n",
      "  Attempting uninstall: verl\n",
      "    Found existing installation: verl 0.1\n",
      "    Uninstalling verl-0.1:\n",
      "      Successfully uninstalled verl-0.1\n",
      "Successfully installed verl-0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/volcengine/verl verl_repo\n",
    "!cd /notebooks && pip3 install -e . -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T19:38:08.482864Z",
     "iopub.status.busy": "2025-01-10T19:38:08.482256Z",
     "iopub.status.idle": "2025-01-10T19:38:08.487459Z",
     "shell.execute_reply": "2025-01-10T19:38:08.486808Z",
     "shell.execute_reply.started": "2025-01-10T19:38:08.482837Z"
    },
    "id": "mOBX8Jqc-ZBe"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "try:\n",
    "  assert torch.cuda.is_available() is True\n",
    "except AssertionError:\n",
    "  print(\"Please start the machine with a GPU\")\n",
    "\n",
    "try:\n",
    "  import verl\n",
    "except Exception as e:\n",
    "  print(\"Please install verl via pip and restart the kernel\")\n",
    "  raise e\n",
    "\n",
    "import flash_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9mawNxDfo3Uu"
   },
   "source": [
    "# Load Pretrained Language Model\n",
    "\n",
    "verl supports models available in Huggingface transformers (as well as custom Megatron models).\n",
    "\n",
    "Let's download the model first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404,
     "referenced_widgets": [
      "763679906f9248a7a5f4c8de952d98ae",
      "b319db13c64b43a38250342c81708f70",
      "5110a596739443a8a640cfd50030644b",
      "e93bf508749940909c3233904e898497",
      "b45a42483d64410ba245feda17ae3e16",
      "538e82daa19140098a4053da6e23de45",
      "6b14f827b15f4e34be6590a5d2085b64",
      "07f455e5e6dd45b7ba52f78bfc7ec7d6",
      "fdf06125a50249b8878dbf01993306f4",
      "0ab915aba5e14e5bba7ba1c22a682b89",
      "2749b87567ea4b6cbc4cf825e2282615",
      "645fee7bcccd42a794e4aa889c1fe145",
      "aa19071cede44a089d7f3b19227d51e0",
      "412349b6e00b4994bc3f63f8405b3ec2",
      "a921f9b0d3c74381b75aa60f4d1cac1c",
      "b707bf4c56744f05ac9245b07f6d1788",
      "252e651f687e47f3bd20518f2ac5fb9f",
      "835a6a0a56554d158ee40ccc5ccdffc5",
      "be14bccf9f114d9f839c805afef08f61",
      "52268a2d657b4e19badd66f781f68d93",
      "06873240926949d98e13872546c5231d",
      "936061cb57ad445195efc0aa24dd8d66",
      "144df34a87334a6d8eb13055e7a9b9e4",
      "1e9ee1c383074f638a688b029d72bc79",
      "5cfeadb8ff394f38ac2e23f1a66beeb3",
      "0eeef594fb564491ad8d80f86a8fbfdc",
      "771c5ca9460f4539b30f452dd3f36b12",
      "fab6aab315214fcb884529a4dbf84fe5",
      "06e1b9b5d49d4ee3ab8d1a523659bcbf",
      "e3848f0a11f8472fba3ecb624bc86dd9",
      "c7b67dd574ad4c15b36930047553e9d3",
      "9fbafd9fc26748b7889b5c52600f80a8",
      "889e01d618544f7c9a9d748730255007",
      "69e57962129241a689cfd2933b64127c",
      "4bdbe0a8bb434bfc8e2172ecb5189705",
      "b0bbbf7f9f264dfda2c0d6775567e446",
      "6c9485ecc56f4027ad8f3824554e3968",
      "3447ed64518746cabb0176348fc88d96",
      "35e124a16d2945ddbb3ade95ef2b5519",
      "7de86c10755f4e0da7974bdf1815a85d",
      "4957b3690466495997721afab68ad93a",
      "9e2c1dcd2cd643bbb941d6697fcc75a0",
      "b10402691cc3480693dcf49d19336c72",
      "f0350562775a4c4ca83772a78d05122b",
      "1a382959fdeb4554827397823284d2fa",
      "f52d7af1a82249a3aa7785476e10c2ad",
      "afcc65785fef4b71b03ac83a4b14d97f",
      "c0b19ca098a443598c662921832e8799",
      "ca24445f8af44c8397f12d15d66eebf5",
      "6cd310d2188d424eb20c3bf83ac34f56",
      "ddecda628c6a4a5680b4241633153ebd",
      "e49f1b46d8ae4c3e8f894b1f411922b9",
      "0c9b8ffe4b8c4b5ca72a21cc54a1feb9",
      "c3651669cb084d86b9b8c427c665d185",
      "35bacfb8aa4c4a25bf8ce2d13a00f2b8",
      "c1020ed4d8a44747838ed59287d284ed",
      "a726ef24d10c42bf859e4c76cebde672",
      "40259328dd5e4256939d7b1a3f038d98",
      "ee0b85738cbf4376a6427fadbdecfad7",
      "1491cbb53c6e4bfb9d17cf123dea83dd",
      "5c8c3c4d700540f089f671d4f5d0dd9f",
      "7c45a87d87f44b2384a4fd316ae36663",
      "866c770e39b64dfd9764de755f6a9ec5",
      "2babfcd555104f9d8ecf98e164ec40fc",
      "7920655156a44e629514673dde2b9663",
      "c24df93c305e42cdbaed3d6111d72010",
      "c0e97dba53284330b0fb8cefc852d552",
      "4d1a260957214732940766c874d3a02b",
      "89a180c90767474b8e699e264620666e",
      "7363ebea3a3a4f55b69b2d813c3b2fa5",
      "d49791321218419d8b7af314dd904777",
      "e6b66ca90c9c4b0ead5153e4a07cdc86",
      "3e1dd2fd3bb049ab83aa987d748f5b9e",
      "a1255e85757e495a86ae366857fb64f1",
      "6f3742161c4f4bcc891c82aff7ece69f",
      "e9f9be6fa1744f3380d21c451bc81555",
      "c5024f35870446a0ae8fd747101ab719"
     ]
    },
    "execution": {
     "iopub.execute_input": "2025-01-10T19:21:07.298750Z",
     "iopub.status.busy": "2025-01-10T19:21:07.298214Z",
     "iopub.status.idle": "2025-01-10T19:21:45.040927Z",
     "shell.execute_reply": "2025-01-10T19:21:45.040356Z",
     "shell.execute_reply.started": "2025-01-10T19:21:07.298718Z"
    },
    "id": "k8FsgBYnpR-R",
    "outputId": "57e0e9ae-2c9e-498d-849f-7eafe59c4c03"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-10 19:21:09.729079: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-10 19:21:09.729231: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-10 19:21:10.017069: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-10 19:21:10.278650: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-10 19:21:12.288539: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4229e42bd9484d1b9f41d4f160a9efe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/659 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ee529c618e46c49eba1c2923251789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc9e63aeda7645c887e370c6156c698c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14599de0457c4abca8d878e95d574cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba52917ac31424aad7662ac4f0c6803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3a8bc65e7743b6bafae24479aae03c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a034bb61b4e47dbaae98a3469cf8631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.text_generation.TextGenerationPipeline at 0x7efc64e35ed0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.pipeline('text-generation', model='Qwen/Qwen2.5-0.5B-Instruct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zWlDQ6EjnBWz"
   },
   "source": [
    "# Dataset preparation\n",
    "\n",
    "We train with the Grade School Math 8K (GSM8k) task in this demo. The dataset is downloaded from huggingface [gsm8k](https://huggingface.co/datasets/openai/gsm8k) and below are some samples:\n",
    "\n",
    "\n",
    "**Prompt**\n",
    "\n",
    "Katy makes coffee using teaspoons of sugar and cups of water in the ratio of 7:13. If she used a total of 120 teaspoons of sugar and cups of water, calculate the number of teaspoonfuls of sugar she used.\n",
    "\n",
    "**Solution**\n",
    "\n",
    "The total ratio representing the ingredients she used to make the coffee is 7+13 = <<7+13=20>>20 Since the fraction representing the number of teaspoons she used is 7/20, she used 7/20120 = <<7/20120=42>>42 #### 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-10T19:23:56.559858Z",
     "iopub.status.busy": "2025-01-10T19:23:56.559091Z",
     "iopub.status.idle": "2025-01-10T19:24:02.362222Z",
     "shell.execute_reply": "2025-01-10T19:24:02.361308Z",
     "shell.execute_reply.started": "2025-01-10T19:23:56.559780Z"
    },
    "id": "AgRCvb6V6B3A",
    "outputId": "f45c7f69-2f81-4b19-98de-8dc4b869736d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|████████| 8/8 [00:00<00:00, 184.34ba/s]\n",
      "Creating parquet from Arrow format: 100%|████████| 2/2 [00:00<00:00, 272.25ba/s]\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ~/data/gsm8k\n",
    "!python3 /notebooks/examples/data_preprocess/gsm8k.py --local_dir ~/data/gsm8k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPZZKBxunAoj"
   },
   "source": [
    "# the reward\n",
    "\n",
    "We use a rule-based reward model. We force the model to produce a final answer following 4 `#` as shown in the solution. We extract the final answer from both the solution and model's output using regular expression matching. We compare them and assign a reward of 1 to correct answer, 0.1 to incorrect answer and 0 to no answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-10T19:24:06.737019Z",
     "iopub.status.busy": "2025-01-10T19:24:06.736706Z",
     "iopub.status.idle": "2025-01-10T19:24:06.748488Z",
     "shell.execute_reply": "2025-01-10T19:24:06.747507Z",
     "shell.execute_reply.started": "2025-01-10T19:24:06.736992Z"
    },
    "id": "SjjLVuO60WD1",
    "outputId": "affb562c-7f6c-41f7-ef47-4dfea0020e90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def compute_score(solution_str, ground_truth, method='strict', format_score=0., score=1.):\n",
      "    \"\"\"The scoring function for GSM8k.\n",
      "\n",
      "    Reference: Trung, Luong, et al. \"Reft: Reasoning with reinforced fine-tuning.\" Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2024.\n",
      "\n",
      "    Args:\n",
      "        solution_str: the solution text\n",
      "        ground_truth: the ground truth\n",
      "        method: the method to extract the solution, choices are 'strict' and 'flexible'\n",
      "        format_score: the score for the format\n",
      "        score: the score for the correct answer\n",
      "    \"\"\"\n",
      "    answer = extract_solution(solution_str=solution_str, method=method)\n",
      "    if answer is None:\n",
      "        return 0\n",
      "    else:\n",
      "        if answer == ground_truth:\n",
      "            return score\n",
      "        else:\n",
      "            return format_score\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "from verl.utils.reward_score.gsm8k import compute_score as gsm8k_reward\n",
    "print(inspect.getsource(gsm8k_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPBGPdSD0sCF"
   },
   "source": [
    "# Run the RL Pipeline\n",
    "Let's start with the Proximal Policy Optimization (PPO) algorithm,  one of the most widely used methods for post-training large language models.\n",
    "\n",
    "The main entry point of the PPO algorithm example is: `main_ppo.py`. A detailed guide to understanding the code architecture of `main_ppo.py` is available [here](https://verl.readthedocs.io/en/latest/examples/ppo_code_architecture.html).\n",
    "\n",
    "In this tutorial, we will demonstrate how to run the PPO algorithm with **Qwen 2.5-0.5B** by setting:\n",
    "- `trainer.n_gpus_per_node`: Number of GPUs per node.\n",
    "\n",
    "- `actor_rollout_ref.rollout.tensor_model_parallel_size`: TP size for rollout. Only effective for vllm.\n",
    "\n",
    "- `actor_rollout_ref/critic.model.path`: Huggingface model path. This can be either local path or HDFS path. For HDFS path, we provide utils to download it to DRAM and convert the HDFS path to local path.\n",
    "\n",
    "- `data.train_batch_size`: Batch size sampled for one training iteration of different RL algorithms.\n",
    "\n",
    "- `data.max_prompt_length`: Maximum prompt length. All prompts will be left-padded to this length. An error will be reported if the length is too long.\n",
    "\n",
    "- `data.max_response_length`: Maximum response length. Rollout in RL algorithms (e.g. PPO) generates up to this length.\n",
    "\n",
    "- `actor_rollout_ref.actor.ppo_mini_batch_size`: One sample is split into multiple sub-batches with batch_size=ppo_mini_batch_size for PPO updates.\n",
    "\n",
    "- `actor_rollout_ref/critic.actor.ppo_micro_batch_size`: Similar to gradient accumulation, the micro_batch_size for one forward pass, trading speed for GPU memory.\n",
    "\n",
    "The full configuration explanation is available [here](https://verl.readthedocs.io/en/latest/examples/config.html).\n",
    "\n",
    "The training may take long time to finish. It will output:\n",
    "\n",
    "- generated sentences.\n",
    "\n",
    "- step information with RL metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T19:25:53.313010Z",
     "iopub.status.busy": "2025-01-10T19:25:53.312220Z",
     "iopub.status.idle": "2025-01-10T19:25:54.528774Z",
     "shell.execute_reply": "2025-01-10T19:25:54.527534Z",
     "shell.execute_reply.started": "2025-01-10T19:25:53.312978Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip3 list | grep flash-attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-10T19:38:31.144912Z",
     "iopub.status.busy": "2025-01-10T19:38:31.144152Z",
     "iopub.status.idle": "2025-01-10T19:39:13.339922Z",
     "shell.execute_reply": "2025-01-10T19:39:13.338695Z",
     "shell.execute_reply.started": "2025-01-10T19:38:31.144881Z"
    },
    "id": "GvyEebBB4eCA",
    "outputId": "a0bb8f75-6f79-456c-c71f-254c84503763"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-10 19:38:36,036\tERROR utils.py:535 -- Unexpected error calculating docker cpuset ids.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/utils.py\", line 532, in _get_docker_cpus\n",
      "    cpu_ids.append(int(num_or_range))\n",
      "                   ^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: '\\n'\n",
      "2025-01-10 19:38:36,230\tINFO worker.py:1821 -- Started a local Ray instance.\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m {'actor_rollout_ref': {'actor': {'clip_ratio': 0.2,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                  'entropy_coeff': 0.001,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                  'fsdp_config': {'grad_offload': False,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                                  'optimizer_offload': False,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                                  'param_offload': False,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                                  'wrap_policy': {'min_num_params': 0}},\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                  'grad_clip': 1.0,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                  'optim': {'lr': 1e-06,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                            'lr_warmup_steps_ratio': 0.0,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                            'min_lr_ratio': None,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                            'total_training_steps': -1,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                            'warmup_style': 'constant'},\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                  'ppo_epochs': 1,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                  'ppo_micro_batch_size': 1,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                  'ppo_mini_batch_size': 64,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                  'shuffle': True,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                  'strategy': 'fsdp'},\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                        'hybrid_engine': True,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                        'model': {'enable_gradient_checkpointing': False,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                  'external_lib': None,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                  'override_config': {},\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                  'path': 'Qwen/Qwen2.5-0.5B-Instruct'},\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                        'ref': {'fsdp_config': {'param_offload': False,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                                'wrap_policy': {'min_num_params': 0}},\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                'log_prob_micro_batch_size': 1},\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                        'rollout': {'do_sample': True,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                    'dtype': 'bfloat16',\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                    'enforce_eager': True,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                    'free_cache_engine': True,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                    'gpu_memory_utilization': 0.4,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                    'ignore_eos': False,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                    'load_format': 'dummy_dtensor',\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                    'log_prob_micro_batch_size': 1,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                    'max_num_batched_tokens': 8192,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                    'max_num_seqs': 1024,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                    'n': 1,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                    'name': 'vllm',\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                    'prompt_length': 512,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                    'response_length': 256,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                    'temperature': 1.0,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                    'tensor_model_parallel_size': 1,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                    'top_k': -1,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                    'top_p': 1}},\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m  'algorithm': {'adv_estimator': 'gae',\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                'gamma': 1.0,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                'kl_ctrl': {'kl_coef': 0.001, 'type': 'fixed'},\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                'kl_penalty': 'kl',\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                'lam': 1.0},\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m  'critic': {'cliprange_value': 0.5,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m             'forward_micro_batch_size': 1,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m             'grad_clip': 1.0,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m             'model': {'enable_gradient_checkpointing': False,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                       'external_lib': None,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                       'fsdp_config': {'grad_offload': False,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                       'optimizer_offload': False,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                       'param_offload': False,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                       'wrap_policy': {'min_num_params': 0}},\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                       'override_config': {},\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                       'path': 'Qwen/Qwen2.5-0.5B-Instruct',\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                       'tokenizer_path': 'Qwen/Qwen2.5-0.5B-Instruct'},\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m             'optim': {'lr': 1e-05,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                       'lr_warmup_steps_ratio': 0.0,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                       'min_lr_ratio': None,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                       'total_training_steps': -1,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                       'warmup_style': 'constant'},\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m             'ppo_epochs': 1,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m             'ppo_micro_batch_size': 1,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m             'ppo_mini_batch_size': 64,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m             'shuffle': True,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m             'strategy': 'fsdp'},\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m  'data': {'max_prompt_length': 512,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m           'max_response_length': 256,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m           'prompt_key': 'prompt',\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m           'return_raw_chat': False,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m           'return_raw_input_ids': False,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m           'tokenizer': None,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m           'train_batch_size': 256,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m           'train_files': '/root/data/gsm8k/train.parquet',\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m           'val_batch_size': 1312,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m           'val_files': '/root/data/gsm8k/test.parquet'},\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m  'reward_model': {'enable': False,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                   'max_length': None,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                   'micro_batch_size': 64,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                   'model': {'external_lib': None,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                             'fsdp_config': {'min_num_params': 0,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                                             'param_offload': False},\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                             'input_tokenizer': 'Qwen/Qwen2.5-0.5B-Instruct',\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1'},\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m                   'strategy': 'fsdp'},\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m  'trainer': {'critic_warmup': 0,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m              'default_hdfs_dir': None,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m              'default_local_dir': 'checkpoints/verl_examples/gsm8k',\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m              'experiment_name': 'gsm8k',\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m              'logger': ['console'],\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m              'n_gpus_per_node': 1,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m              'nnodes': 1,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m              'project_name': 'verl_examples',\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m              'save_freq': 10,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m              'test_freq': 10,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m              'total_epochs': 15,\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m              'val_before_train': False}}\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m original dataset len: 7473\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m filter dataset len: 7473\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m original dataset len: 1319\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m filter dataset len: 1319\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m Size of train dataloader: 29\n",
      "\u001b[36m(main_task pid=2009)\u001b[0m Size of val dataloader: 1\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m Critic overriding config {'bos_token_id': None, 'eos_token_id': 151645, 'pad_token_id': 151643}\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained(\"openai/whisper-tiny\", attn_implementation=\"flash_attention_2\", torch_dtype=torch.float16)`\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m /usr/local/lib/python3.11/dist-packages/torch/distributed/fsdp/_init_utils.py:440: UserWarning: FSDP is switching to use `NO_SHARD` instead of ShardingStrategy.FULL_SHARD since the world size is 1.\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m Qwen2ForCausalLM contains 494.03M parameters\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m Before critic FSDP, memory allocated (GB): 0.0, memory reserved (GB): 0.0\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m NCCL version 2.20.5+cuda11.0\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m After critic FSDP, memory allocated (GB): 1.8410840034484863, memory reserved (GB): 2.95703125\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m Total steps: 435, num_warmup_steps: 0\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m Model config after override: Qwen2Config {\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"_name_or_path\": \"Qwen/Qwen2.5-0.5B-Instruct\",\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"architectures\": [\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m     \"Qwen2ForCausalLM\"\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   ],\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"attention_dropout\": 0.0,\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"eos_token_id\": 151645,\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"hidden_act\": \"silu\",\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"hidden_size\": 896,\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"initializer_range\": 0.02,\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"intermediate_size\": 4864,\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"max_position_embeddings\": 32768,\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"max_window_layers\": 21,\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"model_type\": \"qwen2\",\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"num_attention_heads\": 14,\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"num_hidden_layers\": 24,\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"num_key_value_heads\": 2,\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"pad_token_id\": 151643,\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"rms_norm_eps\": 1e-06,\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"rope_scaling\": null,\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"rope_theta\": 1000000.0,\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"sliding_window\": null,\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"tie_word_embeddings\": true,\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"torch_dtype\": \"bfloat16\",\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"transformers_version\": \"4.48.0\",\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"use_cache\": true,\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"use_sliding_window\": false,\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"vocab_size\": 151936\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m }\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m \n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m /usr/local/lib/python3.11/dist-packages/torch/distributed/fsdp/_init_utils.py:440: UserWarning: FSDP is switching to use `NO_SHARD` instead of ShardingStrategy.FULL_SHARD since the world size is 1.\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m Qwen2ForCausalLM contains 494.03M parameters\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x7ff63691af20>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m Model config after override: Qwen2Config {\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"_name_or_path\": \"Qwen/Qwen2.5-0.5B-Instruct\",\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"architectures\": [\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m     \"Qwen2ForCausalLM\"\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   ],\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"attention_dropout\": 0.0,\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"eos_token_id\": 151645,\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"hidden_act\": \"silu\",\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"hidden_size\": 896,\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"initializer_range\": 0.02,\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"intermediate_size\": 4864,\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"max_position_embeddings\": 32768,\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"max_window_layers\": 21,\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"model_type\": \"qwen2\",\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"num_attention_heads\": 14,\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"num_hidden_layers\": 24,\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"num_key_value_heads\": 2,\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"pad_token_id\": 151643,\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"rms_norm_eps\": 1e-06,\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"rope_scaling\": null,\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"rope_theta\": 1000000.0,\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"sliding_window\": null,\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"tie_word_embeddings\": true,\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"torch_dtype\": \"bfloat16\",\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"transformers_version\": \"4.48.0\",\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"use_cache\": true,\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"use_sliding_window\": false,\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   \"vocab_size\": 151936\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m }\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m \n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m /usr/local/lib/python3.11/dist-packages/torch/distributed/fsdp/_init_utils.py:440: UserWarning: FSDP is switching to use `NO_SHARD` instead of ShardingStrategy.FULL_SHARD since the world size is 1.\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m Qwen2ForCausalLM contains 494.03M parameters\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x7ff63691af20>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m Total steps: 435, num_warmup_steps: 0\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m /usr/local/lib/python3.11/dist-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m No module named 'vllm._version'\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   from vllm.version import __version__ as VLLM_VERSION\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m Before building vllm rollout, memory allocated (GB): 4.602716445922852, memory reserved (GB): 5.78125\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m WARNING 01-10 19:39:10 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m /usr/local/lib/python3.11/dist-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   @torch.library.impl_abstract(\"xformers_flash::flash_fwd\")\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m /usr/local/lib/python3.11/dist-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m   @torch.library.impl_abstract(\"xformers_flash::flash_bwd\")\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m local rank 0\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m INFO 01-10 19:39:10 selector.py:224] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
      "\u001b[36m(WorkerDict pid=2123)\u001b[0m INFO 01-10 19:39:10 selector.py:115] Using XFormers backend.\n",
      "Error executing job with overrides: ['data.train_files=/root/data/gsm8k/train.parquet', 'data.val_files=/root/data/gsm8k/test.parquet', 'data.train_batch_size=256', 'data.val_batch_size=1312', 'data.max_prompt_length=512', 'data.max_response_length=256', 'actor_rollout_ref.model.path=Qwen/Qwen2.5-0.5B-Instruct', 'actor_rollout_ref.actor.optim.lr=1e-6', 'actor_rollout_ref.actor.ppo_mini_batch_size=64', 'actor_rollout_ref.actor.ppo_micro_batch_size=1', 'actor_rollout_ref.rollout.log_prob_micro_batch_size=1', 'actor_rollout_ref.rollout.tensor_model_parallel_size=1', 'actor_rollout_ref.rollout.gpu_memory_utilization=0.4', 'actor_rollout_ref.ref.log_prob_micro_batch_size=1', 'critic.optim.lr=1e-5', 'critic.model.path=Qwen/Qwen2.5-0.5B-Instruct', 'critic.ppo_micro_batch_size=1', 'algorithm.kl_ctrl.kl_coef=0.001', 'trainer.logger=[console]', '+trainer.val_before_train=False', 'trainer.default_hdfs_dir=null', 'trainer.n_gpus_per_node=1', 'trainer.nnodes=1', 'trainer.save_freq=10', 'trainer.test_freq=10', 'trainer.total_epochs=15', 'actor_rollout_ref.actor.ppo_micro_batch_size=1', 'critic.ppo_micro_batch_size=1']\n",
      "Traceback (most recent call last):\n",
      "  File \"/notebooks/verl/trainer/main_ppo.py\", line 99, in main\n",
      "    ray.get(main_task.remote(config))\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 2755, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 906, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::main_task()\u001b[39m (pid=2009, ip=10.39.252.151)\n",
      "  File \"/notebooks/verl/trainer/main_ppo.py\", line 184, in main_task\n",
      "    trainer.init_workers()\n",
      "  File \"/notebooks/verl/trainer/ppo/ray_trainer.py\", line 452, in init_workers\n",
      "    self.actor_rollout_wg.init_model()\n",
      "  File \"/notebooks/verl/single_controller/ray/base.py\", line 42, in func\n",
      "    output = ray.get(output)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::WorkerDict.actor_rollout_init_model()\u001b[39m (pid=2123, ip=10.39.252.151, actor_id=94ca64220de9da40ccc6ae9c01000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7ff97e952f10>)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/notebooks/verl/single_controller/ray/base.py\", line 399, in func\n",
      "    return getattr(self.worker_dict[key], name)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/notebooks/verl/single_controller/base/decorator.py\", line 404, in inner\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/notebooks/verl/workers/fsdp_workers.py\", line 291, in init_model\n",
      "    self.rollout, self.sharding_manager = self._build_rollout()\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/notebooks/verl/workers/fsdp_workers.py\", line 233, in _build_rollout\n",
      "    rollout = vLLMRollout(actor_module=self.actor_module_fsdp,\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/notebooks/verl/workers/rollout/vllm_rollout/vllm_rollout.py\", line 91, in __init__\n",
      "    self.inference_engine = LLM(actor_module,\n",
      "                            ^^^^^^^^^^^^^^^^^\n",
      "  File \"/notebooks/verl/third_party/vllm/vllm_v_0_6_3/llm.py\", line 142, in __init__\n",
      "    self.llm_engine = LLMEngine.from_engine_args(model, tokenizer, engine_args)  # TODO: check usagecontext\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/notebooks/verl/third_party/vllm/vllm_v_0_6_3/llm_engine_sp.py\", line 393, in from_engine_args\n",
      "    engine = cls(\n",
      "             ^^^^\n",
      "  File \"/notebooks/verl/third_party/vllm/vllm_v_0_6_3/llm_engine_sp.py\", line 212, in __init__\n",
      "    self.model_executor = executor_class(\n",
      "                          ^^^^^^^^^^^^^^^\n",
      "  File \"/notebooks/verl/third_party/vllm/vllm_v_0_6_3/spmd_gpu_executor.py\", line 71, in __init__\n",
      "    self._init_executor(model, distributed_init_method)\n",
      "  File \"/notebooks/verl/third_party/vllm/vllm_v_0_6_3/spmd_gpu_executor.py\", line 78, in _init_executor\n",
      "    self._init_workers_sp(model, distributed_init_method)\n",
      "  File \"/notebooks/verl/third_party/vllm/vllm_v_0_6_3/spmd_gpu_executor.py\", line 111, in _init_workers_sp\n",
      "    self.worker.init_device()\n",
      "  File \"/notebooks/verl/third_party/vllm/vllm_v_0_6_3/worker.py\", line 163, in init_device\n",
      "    _check_if_gpu_supports_dtype(self.model_config.dtype)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/vllm/worker/worker.py\", line 473, in _check_if_gpu_supports_dtype\n",
      "    raise ValueError(\n",
      "ValueError: Bfloat16 is only supported on GPUs with compute capability of at least 8.0. Your Quadro RTX 4000 GPU has compute capability 7.5. You can use float16 instead by explicitly setting the`dtype` flag in CLI, for example: --dtype=half.\n",
      "\n",
      "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python3 -m verl.trainer.main_ppo \\\n",
    " data.train_files=$HOME/data/gsm8k/train.parquet \\\n",
    " data.val_files=$HOME/data/gsm8k/test.parquet \\\n",
    " data.train_batch_size=256 \\\n",
    " data.val_batch_size=1312 \\\n",
    " data.max_prompt_length=512 \\\n",
    " data.max_response_length=256 \\\n",
    " actor_rollout_ref.model.path=Qwen/Qwen2.5-0.5B-Instruct \\\n",
    " actor_rollout_ref.actor.optim.lr=1e-6 \\\n",
    " actor_rollout_ref.actor.ppo_mini_batch_size=64 \\\n",
    " actor_rollout_ref.actor.ppo_micro_batch_size=1 \\\n",
    " actor_rollout_ref.rollout.log_prob_micro_batch_size=1 \\\n",
    " actor_rollout_ref.rollout.tensor_model_parallel_size=1 \\\n",
    " actor_rollout_ref.rollout.gpu_memory_utilization=0.4 \\\n",
    " actor_rollout_ref.ref.log_prob_micro_batch_size=1 \\\n",
    " critic.optim.lr=1e-5 \\\n",
    " critic.model.path=Qwen/Qwen2.5-0.5B-Instruct \\\n",
    " critic.ppo_micro_batch_size=1 \\\n",
    " algorithm.kl_ctrl.kl_coef=0.001 \\\n",
    " trainer.logger=['console'] \\\n",
    " +trainer.val_before_train=False \\\n",
    " trainer.default_hdfs_dir=null \\\n",
    " trainer.n_gpus_per_node=1 \\\n",
    " trainer.nnodes=1 \\\n",
    " trainer.save_freq=10 \\\n",
    " trainer.test_freq=10 \\\n",
    " trainer.total_epochs=15 \\\n",
    " actor_rollout_ref.actor.ppo_micro_batch_size=1 \\\n",
    " critic.ppo_micro_batch_size=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zSn7lNlZ2vfL"
   },
   "source": [
    "# Stop and clean up resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QuJ-LgdTAPkb",
    "outputId": "64f2ef75-4a6d-4a62-922e-3d09b33a8a44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-10 06:30:42,799 - INFO - NumExpr defaulting to 2 threads.\n",
      "Did not find any active Ray processes.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!ray stop"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06873240926949d98e13872546c5231d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06e1b9b5d49d4ee3ab8d1a523659bcbf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "07f455e5e6dd45b7ba52f78bfc7ec7d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ab915aba5e14e5bba7ba1c22a682b89": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c9b8ffe4b8c4b5ca72a21cc54a1feb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0eeef594fb564491ad8d80f86a8fbfdc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9fbafd9fc26748b7889b5c52600f80a8",
      "placeholder": "​",
      "style": "IPY_MODEL_889e01d618544f7c9a9d748730255007",
      "value": " 242/242 [00:00&lt;00:00, 15.3kB/s]"
     }
    },
    "144df34a87334a6d8eb13055e7a9b9e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1e9ee1c383074f638a688b029d72bc79",
       "IPY_MODEL_5cfeadb8ff394f38ac2e23f1a66beeb3",
       "IPY_MODEL_0eeef594fb564491ad8d80f86a8fbfdc"
      ],
      "layout": "IPY_MODEL_771c5ca9460f4539b30f452dd3f36b12"
     }
    },
    "1491cbb53c6e4bfb9d17cf123dea83dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a382959fdeb4554827397823284d2fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f52d7af1a82249a3aa7785476e10c2ad",
       "IPY_MODEL_afcc65785fef4b71b03ac83a4b14d97f",
       "IPY_MODEL_c0b19ca098a443598c662921832e8799"
      ],
      "layout": "IPY_MODEL_ca24445f8af44c8397f12d15d66eebf5"
     }
    },
    "1e9ee1c383074f638a688b029d72bc79": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fab6aab315214fcb884529a4dbf84fe5",
      "placeholder": "​",
      "style": "IPY_MODEL_06e1b9b5d49d4ee3ab8d1a523659bcbf",
      "value": "generation_config.json: 100%"
     }
    },
    "252e651f687e47f3bd20518f2ac5fb9f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2749b87567ea4b6cbc4cf825e2282615": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2babfcd555104f9d8ecf98e164ec40fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3447ed64518746cabb0176348fc88d96": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35bacfb8aa4c4a25bf8ce2d13a00f2b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "35e124a16d2945ddbb3ade95ef2b5519": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e1dd2fd3bb049ab83aa987d748f5b9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "40259328dd5e4256939d7b1a3f038d98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_866c770e39b64dfd9764de755f6a9ec5",
      "max": 1671839,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2babfcd555104f9d8ecf98e164ec40fc",
      "value": 1671839
     }
    },
    "412349b6e00b4994bc3f63f8405b3ec2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be14bccf9f114d9f839c805afef08f61",
      "max": 988097824,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_52268a2d657b4e19badd66f781f68d93",
      "value": 988097824
     }
    },
    "4957b3690466495997721afab68ad93a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4bdbe0a8bb434bfc8e2172ecb5189705": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_35e124a16d2945ddbb3ade95ef2b5519",
      "placeholder": "​",
      "style": "IPY_MODEL_7de86c10755f4e0da7974bdf1815a85d",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "4d1a260957214732940766c874d3a02b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e6b66ca90c9c4b0ead5153e4a07cdc86",
      "placeholder": "​",
      "style": "IPY_MODEL_3e1dd2fd3bb049ab83aa987d748f5b9e",
      "value": "tokenizer.json: 100%"
     }
    },
    "5110a596739443a8a640cfd50030644b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_07f455e5e6dd45b7ba52f78bfc7ec7d6",
      "max": 659,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fdf06125a50249b8878dbf01993306f4",
      "value": 659
     }
    },
    "52268a2d657b4e19badd66f781f68d93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "538e82daa19140098a4053da6e23de45": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c8c3c4d700540f089f671d4f5d0dd9f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5cfeadb8ff394f38ac2e23f1a66beeb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e3848f0a11f8472fba3ecb624bc86dd9",
      "max": 242,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c7b67dd574ad4c15b36930047553e9d3",
      "value": 242
     }
    },
    "645fee7bcccd42a794e4aa889c1fe145": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_aa19071cede44a089d7f3b19227d51e0",
       "IPY_MODEL_412349b6e00b4994bc3f63f8405b3ec2",
       "IPY_MODEL_a921f9b0d3c74381b75aa60f4d1cac1c"
      ],
      "layout": "IPY_MODEL_b707bf4c56744f05ac9245b07f6d1788"
     }
    },
    "69e57962129241a689cfd2933b64127c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4bdbe0a8bb434bfc8e2172ecb5189705",
       "IPY_MODEL_b0bbbf7f9f264dfda2c0d6775567e446",
       "IPY_MODEL_6c9485ecc56f4027ad8f3824554e3968"
      ],
      "layout": "IPY_MODEL_3447ed64518746cabb0176348fc88d96"
     }
    },
    "6b14f827b15f4e34be6590a5d2085b64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6c9485ecc56f4027ad8f3824554e3968": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b10402691cc3480693dcf49d19336c72",
      "placeholder": "​",
      "style": "IPY_MODEL_f0350562775a4c4ca83772a78d05122b",
      "value": " 7.30k/7.30k [00:00&lt;00:00, 497kB/s]"
     }
    },
    "6cd310d2188d424eb20c3bf83ac34f56": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f3742161c4f4bcc891c82aff7ece69f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7363ebea3a3a4f55b69b2d813c3b2fa5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e9f9be6fa1744f3380d21c451bc81555",
      "placeholder": "​",
      "style": "IPY_MODEL_c5024f35870446a0ae8fd747101ab719",
      "value": " 7.03M/7.03M [00:01&lt;00:00, 6.03MB/s]"
     }
    },
    "763679906f9248a7a5f4c8de952d98ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b319db13c64b43a38250342c81708f70",
       "IPY_MODEL_5110a596739443a8a640cfd50030644b",
       "IPY_MODEL_e93bf508749940909c3233904e898497"
      ],
      "layout": "IPY_MODEL_b45a42483d64410ba245feda17ae3e16"
     }
    },
    "771c5ca9460f4539b30f452dd3f36b12": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7920655156a44e629514673dde2b9663": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c45a87d87f44b2384a4fd316ae36663": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7de86c10755f4e0da7974bdf1815a85d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "835a6a0a56554d158ee40ccc5ccdffc5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "866c770e39b64dfd9764de755f6a9ec5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "889e01d618544f7c9a9d748730255007": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "89a180c90767474b8e699e264620666e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a1255e85757e495a86ae366857fb64f1",
      "max": 7031645,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6f3742161c4f4bcc891c82aff7ece69f",
      "value": 7031645
     }
    },
    "936061cb57ad445195efc0aa24dd8d66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9e2c1dcd2cd643bbb941d6697fcc75a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9fbafd9fc26748b7889b5c52600f80a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1255e85757e495a86ae366857fb64f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a726ef24d10c42bf859e4c76cebde672": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c8c3c4d700540f089f671d4f5d0dd9f",
      "placeholder": "​",
      "style": "IPY_MODEL_7c45a87d87f44b2384a4fd316ae36663",
      "value": "merges.txt: 100%"
     }
    },
    "a921f9b0d3c74381b75aa60f4d1cac1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06873240926949d98e13872546c5231d",
      "placeholder": "​",
      "style": "IPY_MODEL_936061cb57ad445195efc0aa24dd8d66",
      "value": " 988M/988M [00:24&lt;00:00, 40.9MB/s]"
     }
    },
    "aa19071cede44a089d7f3b19227d51e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_252e651f687e47f3bd20518f2ac5fb9f",
      "placeholder": "​",
      "style": "IPY_MODEL_835a6a0a56554d158ee40ccc5ccdffc5",
      "value": "model.safetensors: 100%"
     }
    },
    "afcc65785fef4b71b03ac83a4b14d97f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e49f1b46d8ae4c3e8f894b1f411922b9",
      "max": 2776833,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0c9b8ffe4b8c4b5ca72a21cc54a1feb9",
      "value": 2776833
     }
    },
    "b0bbbf7f9f264dfda2c0d6775567e446": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4957b3690466495997721afab68ad93a",
      "max": 7305,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9e2c1dcd2cd643bbb941d6697fcc75a0",
      "value": 7305
     }
    },
    "b10402691cc3480693dcf49d19336c72": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b319db13c64b43a38250342c81708f70": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_538e82daa19140098a4053da6e23de45",
      "placeholder": "​",
      "style": "IPY_MODEL_6b14f827b15f4e34be6590a5d2085b64",
      "value": "config.json: 100%"
     }
    },
    "b45a42483d64410ba245feda17ae3e16": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b707bf4c56744f05ac9245b07f6d1788": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be14bccf9f114d9f839c805afef08f61": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c0b19ca098a443598c662921832e8799": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c3651669cb084d86b9b8c427c665d185",
      "placeholder": "​",
      "style": "IPY_MODEL_35bacfb8aa4c4a25bf8ce2d13a00f2b8",
      "value": " 2.78M/2.78M [00:01&lt;00:00, 2.42MB/s]"
     }
    },
    "c0e97dba53284330b0fb8cefc852d552": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4d1a260957214732940766c874d3a02b",
       "IPY_MODEL_89a180c90767474b8e699e264620666e",
       "IPY_MODEL_7363ebea3a3a4f55b69b2d813c3b2fa5"
      ],
      "layout": "IPY_MODEL_d49791321218419d8b7af314dd904777"
     }
    },
    "c1020ed4d8a44747838ed59287d284ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a726ef24d10c42bf859e4c76cebde672",
       "IPY_MODEL_40259328dd5e4256939d7b1a3f038d98",
       "IPY_MODEL_ee0b85738cbf4376a6427fadbdecfad7"
      ],
      "layout": "IPY_MODEL_1491cbb53c6e4bfb9d17cf123dea83dd"
     }
    },
    "c24df93c305e42cdbaed3d6111d72010": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c3651669cb084d86b9b8c427c665d185": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5024f35870446a0ae8fd747101ab719": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c7b67dd574ad4c15b36930047553e9d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ca24445f8af44c8397f12d15d66eebf5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d49791321218419d8b7af314dd904777": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ddecda628c6a4a5680b4241633153ebd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e3848f0a11f8472fba3ecb624bc86dd9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e49f1b46d8ae4c3e8f894b1f411922b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6b66ca90c9c4b0ead5153e4a07cdc86": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e93bf508749940909c3233904e898497": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ab915aba5e14e5bba7ba1c22a682b89",
      "placeholder": "​",
      "style": "IPY_MODEL_2749b87567ea4b6cbc4cf825e2282615",
      "value": " 659/659 [00:00&lt;00:00, 27.5kB/s]"
     }
    },
    "e9f9be6fa1744f3380d21c451bc81555": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee0b85738cbf4376a6427fadbdecfad7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7920655156a44e629514673dde2b9663",
      "placeholder": "​",
      "style": "IPY_MODEL_c24df93c305e42cdbaed3d6111d72010",
      "value": " 1.67M/1.67M [00:00&lt;00:00, 1.93MB/s]"
     }
    },
    "f0350562775a4c4ca83772a78d05122b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f52d7af1a82249a3aa7785476e10c2ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6cd310d2188d424eb20c3bf83ac34f56",
      "placeholder": "​",
      "style": "IPY_MODEL_ddecda628c6a4a5680b4241633153ebd",
      "value": "vocab.json: 100%"
     }
    },
    "fab6aab315214fcb884529a4dbf84fe5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fdf06125a50249b8878dbf01993306f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
